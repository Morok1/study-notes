#+TODO: X 0 1 2 | OK
#+TITLE: Tеория типов. Конспект по лекциям Штукенберга Д.Г.

* probleMEMES
  1. 10 билет очень короткий (ну и пусть)
  2. В 10 билете непонятно вообще ничего, алгоритма нету, def похоже
     на let
     Штукенберг пообещал сильно не насиловать по вопросу, но что-то
     похожее можно прочитать в источнике про ML type inference.
  3. 13 билет мало (это ничего)
* Preface and sources
  1. Лекции, данные напрямую Штукенбергом Д.Г.
  2. Конспект самого Штукенберга Д.Г
     https://github.com/shd/tt2014/blob/master/conspect.pdf
  3. Sørensen, Urzyczyn. Lectures on the Curry-Howard Isomorphism
     http://disi.unitn.it/~bernardi/RSISE11/Papers/curry-howard.pdf
  4. ПОМИ РАН презентация
     http://www.compsciclub.ru/csclub/sites/default/files/slides/20110313_systems_of_typed_lambda_calculi_moskvin_lecture06.pdf
  5. Efficient unification algorithm
     http://www.nsl.com/misc/papers/martelli-montanari.pdf
  6. Пирс. Типы в языках программирования.
     http://starling.rinet.ru/~goga/tapl/tapl.pdf
  7. Денотационная семантика Лямбда-исчисления
     http://math.nsc.ru/~asm256/lambda/LambdaDec2012.pdf
  8. The taste of linear logic
     http://r.duckduckgo.com/l/?kh=-1&uddg=http://homepages.inf.ed.ac.uk/wadler/papers/lineartaste/lineartaste-revised.pdf
  9. Stanford encyclopedia -- linear logic
     http://plato.stanford.edu/entries/logic-linear/
  10. Generalizing Hindley-Milner Type Inference Algorithms
      http://webdoc.sub.gwdg.de/ebook/serien/ah/UU-CS/2002-031.pdf
  11. The essence of ML type inference (for H-M constraints)
      http://gallium.inria.fr/~fpottier/publis/emlti-final.pdf
* Ticket 1   Untyped λ, Church-Rosser
** Simple λ-calculus (pre-terms, λ-terms, α-eq)
   Пусть V={v₀, v₁, v₂...} -- набор свободных переменных, тогда
   Λ⁻ := V | (Λ⁻ Λ⁻) | (λV.Λ⁻) -- пред-терм.

   Конструкторы называются, соответственно, переменная, аппликация
   (применение) и абстракция.

   Заранее скажем, что ассоциативность ' ' -- левая, и тело абстракции
   имеет высший приоритет. Скажем, λx.a b c d e = λx.((((a b) c) d)
   e). Еще сахар: λab.A = λa.λb.A.

   Свободные переменные:
   FV(x)    = {x}
   FV(A B)  = FV(A) ∪ FV(B)
   FV(λx.A) = FV(A) \ {x}
   Терм называется замкнутым/закрытым, если FV(T) = {}

   Подстановка N вместо x в M:
   x[x:=N]       = N
   y[x:=N]       = y
   (P Q)[x:=N]   = P[x:=N] Q[x:=N]
   (λx.P)[x:=N]  = λx.P
   (λy.P)[x:=N]  = λz.P[y:=z][x:=N]  если y∈FV(N) или x∈FV(N)
   (λy.P)[x:=N]  = λy.P[x:=N]        otherwise
   Также подстановку можно сделать модно через нотацию Де-Брюина.

   α-эквивалентность (=α) -- наименьшее отношение на Λ⁻, что
   P =α P                 ∀P
   λx.P =α λy.P[x:=y]     если y∉FV(P)

   [M]α = {N∈Λ⁻ | M =α N}
   Λ = Λ⁻/=α = {[M]α | M∈Λ⁻} -- лямбда-терм

   Примечание: отсюда и дальше все термы -- лямбда-термы, а не
   пред-термы, если не написано иначе.

   Определение свободных переменных у лямбда-термов такое же, как и у
   пред-термов (с точностью до очевидных мелких деталей). Подстановка
   определяется так же, кроме подстановки в абстракцию, она на самом
   деле такая:

   (λy.P)[x:=N] = λy.P[x:=N] если x ≠ y, где y∉FV(N).
** β-редукция и свойства
   Определим на λ-термах редукцию:

   →β -- наименьшее одношение на Λ, что
   λx.P     →β λx.P'     если P →β P'
   (P Z)    →β (R W)     если (P →β R и Z = W) или (Z →β W и P = R)
   (λx.P) Q →β P[x:=Q]   если Q свободна для подстановки в P
   относительно x

   Назовем терм вида (λx.P) Q β-редуксом, P[x:=Q] β-contractum (нет
   идей, как перевести правильно).

   Терм T находится в нормальной форме, если ∄T', что T →β T'.

   Определим мультишаговую редкуцию:
   A →→β C, если ∃B₀...Bₙ, что A →β B₀ →β ... →β Bₙ →β C.
   Возможно, что n = 0.

   Примечание: правильный значок для этого отношения -- ↠, но он нигде
   хорошо не отображается, в том числе и у меня.

   Свойства →→β редукции:
   1. Рефлексивность: A →→β A
   2. Транзитивность
   3. A →→β A'  ⇒  (A B) →→β (A' B) ∧ (B A) →→β (B A') ∧ λx.A →→β λx.A'
   4. A →→β A'  ⇒  A[x:=B] →→β A'[x:=B]
   5. A →→β A'  ⇒  C[x:=A] →→β C[x:=A']

   Среди этих утверждений неочевидно только четвертое.
   * Доказательство пункта 4. Без потери общности докажем A →β A' ⇒
     A[x:=B] →→β A'[x:=B].

     Будем также считать, что все связанные переменные отличны от x,
     то есть возьмем какой-то другой терм, α-эквивалентный нашему,
     если связанный x есть.

     Докажем индукцией по разности длин терма и редекса.
     1. Разность = 0
        A = (λy.P) Q; A' = P[y:=Q].
        Tогда A[x:=B] = (λy.P[x:=B]) Q[x:=B] →→β (P[x:=B])[y:=Q[x:=B]] = P[y:=Q][x:=B] = A'[x:=B].
        То есть A[x:=B] →→β A'[x:=B], действительно.
     2. Разность > 0
        Рассмотрим три случая по этому поводу
        1. A = A₀A₁, редекс находится внутри A₀.

           По предположению индукции A₀[x:=B] →→β A₀'[x:=B], тогда
           очевидным образом основное утверждение верно.
        2. A = A₀A₁, редекс находится внутри A₁. Аналогично.
        3. A = λz.A₀, тогда из предположения индукции A₀[x:=B] →
           A₀'[x:=B], тут тоже очевидно получается утверждение с
           помощью правил подстановки.
** Church-Rosser theorem
   Теорема Чёрча-Россера для λ-термов.

   ∀M₁, M₂, M₃ ∈ Λ если M₁ →→ M₂ и M₁ →→ M₃,
   то существует M₄, что M₂ →→ M₄ и M₃ →→ M₄.


   Определим отношение ⇉ (параллельная редукция) на Λ:
   P ⇉ P
   P ⇉ P'           ⇒ λx.P ⇉ λx.P'
   P ⇉ P' && Q ⇉ Q' ⇒ P Q ⇉ P' Q'
   P ⇉ P' && Q ⇉ Q' ⇒ (λx.P)Q ⇉ P'[x:=Q']
   *транзитивности нету*

*** Лемма 1. A →β A' ⇒ A ⇉ A'
     Пусть R -- это редекс, который участвует в A →β A', проведем
     индукцию по разности длин терма А и этого редекса.

     Пусть разность -- 0, тогда A = R = (λx.M) N и в этом случае A ⇉
     A' выводится по четвертому правилу ⇉.

     Пусть разность > 0, тогда по предположению утверждение верно для
     всех пар <терм, редекс>, для которых разность длин терма и
     редекса меньше, чем у A и R.

     1. A = (A₀ A₁), R находится внутри A₀.

        Пусть A₀ →β A₀' по редексу R в A₀, тогда по предположению
        индукции A₀ ⇉ A₀'. С учетом того, что A₁ ⇉ A₁ (аксиома 1), по
        третьей аксиоме получаем

        A = (A₀ A₁) ⇉ (A₀' A₁) = A'
     2. A = (A₀ A₁), R находится внутри A₁. Аналогично.
     3. A = λx.A₀, R находится внутри A₀, тогда по предположению
        индукции A₀ ⇉ A₀', тогда A = λx.A₀ ⇉ λx.A₀' = A'.
*** Лемма 2. A ⇉ A' ⇒ A →→β A'
    Покажем, что для всех 4 аксиом ⇉ верно то же самое.

    Первые три аксиомы (правила) ⇉ верны в силу свойств β-редукции
    доказанных в пункте выше.

    Насчет четвертого правила:

    M →→β M', N →→β N', тогда (λx.M) N →β M[x:=N] →→β M'[x:=N] →→β M'[x:=N'].

    Последние 2 перехода верны в силу тех же свойств →→β.
*** Лемма 3. О подстановке для ⇉. M ⇉ M' ∧ N ⇉ N' ⇒ M[x:=N] ⇉ M'[x:=N']
    1. Частный случай M = M'

       Индукция по числу шагов в построении M.

       1. База. M это переменная y, тогда
          x = y ⇒ x[x:=N] = N ⇉ N' = x[x:=N']
          x ≠ y ⇒ y[x:=N] = y ⇉ y = y[x:=N']
       2. Предположение: утверждение верно для всех термов меньшей
          сложности.

          Если M = PQ, тогда по предположению индукции утв. верно для
          P и Q.

          Тогда по третьему правилу для ⇉:

          M[x:=N] = (PQ)[x:=N] = (P[x:=N])(Q[x:=N]) ⇉
          (P[x:=N'])(Q[x=N']) = (PQ)[x:=N'] = M[x:=N'].

          Если M = λy.P, то используя предположение индукции и тот
          факт, что мы рассматриваем термы с точностью до
          α-эквивалентности, все работает.
    2. Общий случай.

       Докажем индукцией по построениею M ⇉ M'.

       Случай с минимальной длиной вывода уже доказан
       (база). Рассмотрим переход:
       1. Последний шаг вывода это правило 2 для ⇉, то есть P ⇉ P' ⟶
          (M=) λy.P ⇉ λy.P' (=M').

          По предположению индукции P[x:=N] ⇉ P'[x:=N'], откуда по
          правилу 2 получаем то что надо -- (λy.P)[x:=N] ⇉
          (λy.P')[x:=N'].
       2. Последний шаг вывода -- правило 3. Более-менее аналогично.
       3. Последний шаг вывода -- правило 4. P ⇉ P', Q ⇉ Q' ⟶ (M=)
          (λy.P)Q ⇉ P'[y:=Q'] (=M').

          Без ограничения общости скажем, что y∉N, N' и y ≠ x.

          По индукционному предположению:

          P[x:=N] ⇉ P'[x:=N], и для Q такое же.

          Тогда M[x=N] = ((λy.P)Q)[x:=N] = ((λy.P[x:=N])Q[x:=N]) ⇉
          (P'[x:=N'])(y:=Q'[x:=N']) по предп. индукции и аксиомы 4 =
          P'[y:=Q'][x:=N'] = M'[x:=N']
*** Лемма 4. Об обратных.
    * Лемма 4.1. Если x ⇉ M', то M' = x
    * Лемма 4.2. Если λx.P ⇉ M', то ∃ P' что M' = λx.P' и P ⇉ P'
    * Лемма 4.3. Если PQ ⇉ M', то одно из двух:
      1) ∃ P',Q', что M' = P'Q' и P⇉P', Q⇉Q'
      2) P= λx.P₁ и ∃P₁' и Q' что M' = P₁'[x:=Q'], P₁ ⇉ P'₁ и Q ⇉ Q'

    Доказательство:
    1. Для переменной для ⇉ правило только одно -- первое, и оно есть
       тождественное отображение.
    2. Получить лямбду можно только по второму правилу.
    3. Получить аппликацию можно только по 3-4 правилам.
*** Лемма 5. Параллельная редукция конфлюэнтна (удовлетворяет ромбовидному св-ву)
    M ⇉ P, M ⇉ Q, ∃ N, что P ⇉ N, Q ⇉ N.
    Проведем индукцию по сложности M.
    1. M = x, тогда P = Q = x и возьмем N = x.
    2. M = λx.M₁, тогда найдутся P₁ и Q₁, что P = λx.P₁, Q = λx.Q₁, M₁
       ⇉ P₁, M₁ ⇉ Q₁.

       Тогда по индукционному предположению найдется N₁, что P₁ ⇉ N₁ и
       Q₁ ⇉ N₁ и тогда P = λx.P₁ ⇉ λx.N₁, Q = λx.Q₁ ⇉ λx.N₁, отсюда N
       = λx.N₁ подходит.
    3. M = M₁M₂, придется рассмотреть 4 случая для всех комбинаций
       подпунктов леммы 4.3 -- то, чем могут быть P, Q из условия.
       1. Для P, Q реализуется подслучай (1), то есть существует P₁,
          P₂, Q₁, Q₂ что P = P₁P₂, Q = Q₁Q₂.

          Условие: M₁ ⇉ P₁, M₂ ⇉ P₂, M₁ ⇉ Q₁, M₂ ⇉ Q₂.

          Тогда По предположению индукции P₁, Q₁ ⇉ N₁, P₂, Q₂ ⇉
          N₂. Тогда P = P₁P₂ ⇉ N₁N₂ и Q туда же. N = N₁N₂.
       2. Для P реадизуется (1), для Q (2). То есть:

          ∃ P₁, P₂ что M₁ ⇉ P₁, M₂ ⇉ P₂, P = P₁P₂

          ∃ M₁', Q₁', Q₂, что M₁ = λx.M₁', M₁' ⇉ Q₁', M₂ ⇉ Q₂, Q =
          Q₁'[x:=Q₂]

          Поскольку M₁ = λx.M₁' ⇉ P₁, то в силу леммы 4.3 найдется P₁'
          что P = (λx.P₁')P₂ и M₁' ⇉ P₁'.

          Посмотрим еще раз на M:
          M = (λx.M₁')M₂ ⇉ P = (λx.P₁')P₂
          M = (λx.M₁')M₂ ⇉ Q = Q₁'[x:=Q₂]

          По индукционному предположению найдутся N₁' N₂', что P₁', Q₁' ⇉ N₁' и P₂, Q₂ ⇉ N₂'. Тогда по 4 аксиоме:
          P = (λx.P₁')P₂ ⇉ N₁'[x:=N₂']

          А для Q по лемме о подстановке для ⇉ (Лемма 3):

          Q = Q₁'[x:=Q₂] ⇉ N₁'[x:=N₂']

          Ну и возьмем N = N₁'[x:=N₂']
       3. Случай (2) (1) симметрично предыдущему
       4. Оба терма P, Q удовлетворяют подслучаю (2).

          P = P₁[x:=P₂] ⇉ N₁[x:=N₂]

          Q = Q₁[x:=Q₂] ⇉ N₁[x:=N₂]

          Возьмем N = N₁[x:=N₂]
*** Вывод/заключение
    Пусть M →→β P, M →→β Q. Поскольку A →β B влечет A ⇉ B по лемме 1,
    то существуют две конечные цепочки редукций:

    M ⇉ P₁ ⇉ ... ⇉ Pₙ₋₁ ⇉ P

    M ⇉ Q₁ ⇉ ... ⇉ Qₘ₋₁ ⇉ Q

    Тогда рисуем сеточку, первая цепочка горизонтально, вторая вниз, M
    в верхнем левом узле сетки. По конфлюэнтности отношения ⇉ можем
    найти все остальные члены сетки последовательно, тогда мы можем
    найти пересечение Nₙₘ.

    Поскольку A ⇉ B влечет A →→β B по лемме 2, получаем как раз P, Q
    →→β N.
* Ticket 2   Algebraic types, fixed point, Church paradox
** Algebraic types
   Тип-сумма -- дизъюнктное объединение других типов. (Перечисление типов)
   Тип-произведение -- декартово произведение исходных типов. (Конструктор типов)

   Пример:
   Status = Ok | Error -- тип-сумма
   Кортеж -- тип произведение

   Алгебраический тип -- тип-сумма типов-произведений. (Набор конструкторов)

   Пример:
   List a = Nil | Cons a (List a)
** Normal/applicative reduction order
   Аппликативный порядок редукции: всегда применять редуксы сначала в
   аргументах, а уже потом в самой фукнции (если дерево растет вниз,
   то нижний левый).

   Нормальный порядок редукци: всегда применять редукс сначала
   функции, а потом уже ее аргументов (верхний правый).

   Нормальный порядок редукции редуцирует самый левый (в текстовом представлении)
   редекс.

   * Лемма о нормальном порядке. Eсли терм слабо нормализуем, то может
     быть приведено к нормальной форме нормальным порядком редукции.
** Beta-equality, fixed point combinator
   Отношение бета-эквивалентности (=β) есть транзитивное,
   рефлексивное, симметричное замыкание →β.

   Пример:
   A →β ... →β B ←β ... ←β C →β ... →β D ←β ... ←β E
   A =β E

   Для любого F найдется X такой, что:
   F X =β X

   На деле, существует λ-терм Y, такой, что F (Y F) =β Y F, тогда X = Y F:
   Y = λf.(λx.f (x x)) λx.f (x x)
   Y F = ((λx.F (x x)) (λx.F (x x))) = F (λx.F (x x)) (λx. F (x x)) = F (Y F)

   Для любого M существует F, такой, что
   F =β M[f:=F]

   Возьмем F = Y λf.M
   F = Y λf.M = {по предыдущей лемме} =β (λf.M) (Y λf.M) = (λf.M) F =β M[f:=F]
** Boolean logic, Church numerals, pairs
   Булева логика:
   T = λx.λy.x
   F = λx.λy.y
   chooser = λB.λP.λQ.B P Q (chooser = if then else)

   Видно, что
   (chooser true) P Q  =β P
   (chooser false) P Q =β Q

   Аналогично можно определить:
   not = λa.(a F) T
   xor = λa.λb.a (not b) b

   Пары:
   <A, B> = λx.x A B
   π₁ = λx.λy.x = T
   π₂ = λx.λy.y = F
   <A, B> π₁ =β A
   <A, B> π₂ =β B

   Чёрчевские нумералы:
   Определим fⁿ (n-разовое применение f)
   f⁰(A)   = A
   fⁿ⁺¹(A) = f(fⁿ(A))

   Тогда будем называть cₙ n-тым черчевским нумералом, если:
   cₙ = λf.λx.fⁿ(x)

   Заметим, что для черчевских нумералов есть забавная арифметика:

   isZero = λn.n (λx.F) T
   isZero (λfx.x) = (λfx.x) (λx.F) T = λx.x T = T
   isZero (λfx.f x) = (λfx.f x) (λx.F) T = (λx.(λx.F) x) T = λx.F T = F

   inc = λn.λfx.f (n f x)
   inc λfx.f x = λfx.f ((λfx.f x) f x) = λfx.f (f x)

   plus = λabfx.a f (b f x)
   mul = λabf.a (b f) =β λab.a (plus b) c₀
   pow = λab.b a = λab.a (mul b) c₁

   С помощью пар можно еще сделать вычитание.
   fst a = a π₁
   snd a = a π₂
   dec a = λn.snd(n (λp.<fst p + 1; fst p>) <0, 0>)

   Типа каждый раз с <0, 0> поднимаем наше число до <n, n-1>, потом
   возвращаем второй аргумент.
** Curry paradox
   Давайте создадим какую-нибудь наивную теорию/модель, которая будет
   как-то приятно изоморфна простому λ-исчислению. Допустим следующее:

   Выражения в модели -- лямбда-термы, импликация обозначается
   значком ⊃, на ней мы не определяем никакие отношения, бета редукция
   идет по аргументам, связку не меняя.

   ⊢ a ⊃ b, если a =β b
   ⊢ b ⊃ b, если a =β b
   ⊢ (a ⊃ a ⊃ b) ⊃ (a ⊃ b), очень естественное свойство, если думать о ⊃ как о редукции.

   Тогда наблюдаем следующий забавный спецэффект:
   Φₐ = λx.(x x ⊃ a)
   Fₐ = ΦₐΦₐ = (λx.x x ⊃ a)(λx.x x ⊃ a) →β (λx.x x ⊃ a)(λx.x x ⊃ a) ⊃ a = Fₐ ⊃ a
   Fₐ →β Fₐ ⊃ a
   Fₐ ⊃ (Fₐ ⊃ a)                по 1 аксиоме
   (Fₐ ⊃ (Fₐ ⊃ a)) ⊃ Fₐ ⊃ a     2 аксиома
   Fₐ ⊃ a                       Modus Ponens
   Fₐ                           бета-эквивалентно Fₐ ⊃ a, 1 аксиома
   a                            Modus Ponens

   Таким образом, мы показали, что данная система слишком мощная и
   вообще противоречивая.

   Более упрощенная версия: Fₐ ⊃ a = Fₐ -- это и есть парадокс Карри
   (если это утверждение истинно, то луна сделана из зеленого сыра).

   Данный пример наглядно показывает, что наивное применение правил
   может привести к проблемам.
* Ticket 3   λ→, Church/Curry, Lemmas, C-H
** Просто типизированное λ→ á la Curry
   Грамматика для типов: Π = U | Π → Π, где U - множество простых
   (атомарных) типов.

   Контекстом будем называть множество пар вида xₙ:τₙ, причем xᵢ≠xⱼ
   для i≠j.

   dom(Γ) = {xᵢ | xᵢ:τᵢ ∈ Γ}
   range(Г) = {τᵢ | xᵢ:τᵢ ∈ Γ}

   Аксиомы типизации (тут и дальше ⟶ обозначает длинную горизонтальную черту вывода):
   ()                 ⟶ Г,x:τ ⊢ x:τ
   Γ ⊢ M:σ→τ; Γ ⊢ N:σ ⟶ Γ ⊢ (M N):τ
   Γ,x:σ ⊢ M:τ        ⟶ Г ⊢ λx.M: σ → τ

   M ∈ Λ типизируемо, если существуют Γ и σ, что Γ ⊢ M:σ.

   Таким образом, будем называть просто типизированным λ-исчислением
   тройку (Λ, Π, ⊢). Еще обозначается как λ→.

   Определим подстановку типа τ вместо α в тип σ (σ[α:=τ]):
   α[α:=τ]         = τ
   β[α:=τ]         = β      если α ≠ β
   (σ₁ → σ₂)[α:=τ]  = σ₁[α:=τ] → σ₂[α:=τ]

   Нотация Γ[α:=τ] обозначает {(x:σ[α:=τ] | (x:σ) ∈ Γ}
** Базовые леммы для λ→
*** 2 Лемма о свободных переменных.
    Пусть Γ ⊢ M:σ, тогда верно следующее:
    1. Γ ⊆ Γ' ⇒ Г' ⊢ M:σ
    2. FV(M) ⊆ dom(Γ)
    3. Γ' ⊢ M:σ где dom(Γ')=FV(M) и Γ' ⊆ Γ

    Докажем:
    1. Индукция по доказательству (по длине, рассмотрим последний
       элемент..). В доказательстве Γ' ⊢ M:σ содержатся все
       необходимые посылки, и даже больше.
    2. Аналогично
    3. Аналогично
*** 2 Лемма о генерации
    1. Γ ⊢ x:σ     ⇒ x:σ ∈ Γ
    2. Γ ⊢ (M N):σ ⇒ ∃τ | Γ ⊢ M:τ → σ и Γ ⊢ N:τ
    3. Γ ⊢ λx.M:σ  ⇒ ∃τ,ρ | σ = τ → ρ, Γ ⊢ x:τ, Γ ⊢ M:ρ

    Доказательство очевидно по индукции по длине доказательства.
*** 2 Лемма о подстановке
    Из замененного контекста выводится замененный тип. Замена подтерма
    термом такого же типа не меняет тип выражения.

    1. Γ ⊢ M:σ               ⇒ Γ[α:=τ] ⊢ M:σ[α:=τ]
    2. Γ,x:τ ⊢ M:σ и Γ ⊢ N:τ ⇒ Γ ⊢ M[x:=N]:σ

    Доказательство по индукции.
*** 2 Лемма о редукции
    Γ ⊢ M:σ и M →β N ⇒ Γ ⊢ N:σ

    Доказательство по индукции доказательства M →β N с помощью
    предыдущих двух лемм.  Аналогично верно для →→β. (subject
    reduction)

    *Очень важно отметить*, что следующее (похожее) свойство *неверно*
    в λ→:

    Γ ⊢ N:σ и M →→β N ⇒ Γ ⊢ M:σ (subject expansion)
*** 2 Теорема Чёрча-Россера для λ→
    Пусть Γ ⊢ M:σ; Если M →→β N и M →→β N', то существует L, что N →→β
    L и N' →→β L, причем Г ⊢ N:σ.

    Доказательство общего факта вывода аналогично доказательству в
    нетипизированном лямбда-исчислении, вывод типа доказывается по
    лемме о редукции.
** Y-комбинатор
   Покажем нетипизируемость Y-комбинатора (с помощью леммы о
   генерации).

   Ω = (λx.x x) (λx.x x)

   Допустим, что типизируется. Тогда для λx.x x должны существовать a,
   b, что a → b, тогда x:a, (x x):b, но x:c → b из второго.

   Y = λf.(λx.f x x) (λx.f x x)

   Пусть Y:a
   ∃b, c, что f:b, ((λx.f x x) (λx.f x x)) : c
   ∃d,    что (λx.f x x) : d → c, (λx.f x x) : d
   ∃e     что ОЧЕНЬ ДОЛГО ВЫВОДИТЬ РУКАМИ

   Вот что выдает type-inference алгоритм:
   τ10 = τ8
   τ11 = τ8
   →(τ11 →(τ10 τ9)) = τ1
   τ3 = →(τ8 τ9)
   τ6 = τ4
   τ7 = τ4
   →(τ7 →(τ6 τ5)) = τ1
   →(τ3 τ2) = →(τ4 τ5)
   τ0 = →(τ1 τ2)
   Оно где-то ломается, точно.
** λ→ á la Church
   Имеем то же самое, только теперь обзаведемся наборами Vσ -- набор
   свободных переменных типа σ. Тогда грамматика такая:

   x ∈ Vσ             ⇒ x ∈ Λσ
   M ∈ Λσ→τ & N ∈ Λσ  ⇒ M N ∈ Λτ
   M ∈ Λτ & x ∈ Λσ    ⇒ λx^σ.M ∈ Λσ→τ

   Псевдо-терм:
   Λπ := V | (λx:Π.Λπ) | (Λπ Λπ)

   Отношение типизируемости:
   ()                 ⟶ Г,x:τ ⊢* x:τ
   Γ,x:σ ⊢ M:τ        ⟶ Г ⊢ (λx:σ.M):σ → τ
   G ⊢ M:σ→τ; Γ ⊢ N:σ ⟶ Γ ⊢ (M N):τ
   Где x∉dom(Γ) для первого и второго правила.

   Просто типизированное лямбда-исчисление по Чёрчу -- это <Λπ, Π, ⊢*>.

   Все отношения типа FV и все леммы доказыавются с точностью до
   символов в абстракции тем же образом, что и для исчисления по
   Карри. Доказательство теоремы Чёрча-Россера такое же (надеюсь),
   следим за отношением термов типа λx:α.P и λx:β.P.

   Существенное отличие от исчисления по Карри -- следующая лемма (в
   Карри ее нету).
   * Лемма о уникальности типов
     Γ ⊢* M:σ, M:τ ⇒ σ = τ
     Γ ⊢* M:σ, N:τ ⇒ (M =β N) ⇒ σ = τ.

     Доказательство первого факта по индукции по структуре M.

     Для доказательства второго факта воспользуемся теоремой
     Чёрча-Россера. ∃ L: M →→β L, N →→β L, тогда Γ ⊢ L:σ, L:τ (по
     лемме о subject reduction), что есть пункт 1.

     В исчислении по Карри ето не работает. Контрпример: id: a →
     a. id: (a → a) → (a → a). В черче такие id будут разными (типа
     λx:a.x и λx:a→a.x).
** Связь между исчислением по Карри и по Чёрчу
   Разница между простым исчислением по Kарри и Чёрчу очень мала, и в
   основном относится к реализации языков программирования, потому что
   в некоторых языках нужно явно указывать типы, в некоторых не нужно.

   Установим взаимосвязь между системами типизации по Чёрчу и по
   Карри:

   Определим отношение стирание типа: er(X)
   er(x)      = x
   er(M N)    = er(M) er(N)
   er(λx:σ.M) = λx.er(M)

   * Лемма о стирании:
     Пусть M, N ∈ Λπ.
     1. M →β N   ⇒ er(M) →β er(N)
     2. Γ ⊢* M:σ ⇒ Γ ⊢ er(M):σ

     Доказательство:
     1. В первом с помощью индукции по M показывается:

        er(M[x:=N]) = er(M)[x:=er(N)]

        Потом с помощью этого знания доказывается само утверждения при
        помощи индукции по доказательству M →β N с помощью утверждения
        выше.
     2. По индукции вывода Γ ⊢* M:σ

   * Лемма о подъеме:
     ∀M, N ∈ Λ
     1. M →β N ⇒ ∀M'∈ Λπ что er(M') = M существует N'∈Λπ что er(N') = N и M' →β N'.
     2. Γ ⊢ M:σ ⇒ ∃M'∈Λπ что er(M') = M и Γ ⊢* M':σ

     Доказательства по индукции по выводу M →β N и Γ ⊢ M:σ
     соответственно
** Изоморфизм Карри-Ховарда
   Рассмотрим импликативный фрагмент ИИВ.

   Будем рассматривать термы вида T = V | V → V, что изоморфно типам.

   Пусть в импликативном фрагменте ИИВ работают следующие правила
   вывода:

   1i. ()               ⟶ Γ, φ ⊢ φ
   2i. Γ ⊢ φ → ψ; Γ ⊢ φ ⟶ Γ ⊢ ψ
   3i. Γ, σ ⊢ τ         ⟶ Γ ⊢ σ → τ

   Тут и далее ⊢ обозначает вывод в ИИВ, везде где написано ⊢i -- это
   оно же. В большинстве случаев i опускается.

   Напомним также для удобства правила вывода в λ→:
   1l. ()                 ⟶ Δ, x:τ ⊢ x:τ
   2l. G ⊢ M:σ→τ; Δ ⊢ N:σ ⟶ Δ ⊢ (M N):τ
   3l. Δ,x:σ ⊢ M:τ        ⟶ Δ ⊢ λx.M: σ → τ

   Заметим исключительную схожесть аксиом.

   Теорема об изоморфизме.
   1. Γ ⊢ M:φ ⇒ types(Γ) ⊢i φ
   2. Γ ⊢i φ ⇒ ∃ M ∈ Λ, что {xₜ:t|t∈Γ} ⊢ M:φ

   Доказательство:
   1. Проведем индукцию по выводу терма M:φ. Будем заменять правила
      вывода в Λ на соответсвтующие в ИИВ.

      1l → 1i
      2l → 2i
      3l → 3i

      Просто стираем термы и получаем валидное доказательство в ИИВ.
   2. Будем строить терм M индукцией по доказательству в ИИВ:
      1. Правило 1i.

         Применим правило 1l с точностью до операции "выкинем из
         контекста пару x:τ" если она там уже имеется, чтобы не
         нарушать правила невхождения пары в 1l.
      2. Правило 2i. Банально оттранслируем.
      3. Правило 3i.

         Γ, σ ⊢ τ ⟶ Γ ⊢ σ → τ
         1. σ ∈ Γ, тогда по предположению индукции Δ ⊢ M:σ, и можно
            показать следующее:

            Δ ⊢ M:ψ
            Δ, x:φ ⊢ M:ψ
            Δ ⊢ (λx.M) : φ → ψ
         2. σ ∉ Γ, просто применим 3l.

   Примечание: утверждается, что можно расширить изоморфизм с
   импликативного фрагмента ИИВ на все ИИВ. Тогда мы должны
   запостулировать всякие связки типа ¬, ∨, ∧ не используя квантора
   всеобщности, мы это уже делали в билете 2 алгебраическими типами.
* Ticket 4   Type existence/inhabitation, unification, type inference for λ→
  Всего у нас есть три задачи: проверка типа, вывод/синтез типа,
  обитаемость типа.

  Вывод -- получение типа по терму, обитаемость -- проверка на то,
  существует ли терм данного типа. Задача проверки сводится к выводу.

  Для λ→ все три задачи разрешимы.

  Синтез/проверка -- для Чёрча просто строим дерево вывода, спускаясь
  вниз и достраивая сам терм. Для Карри вывод решается построением
  системы и ее унификацией, а проверка -- построением типа и его
  сравнением с тем, что дан.

  Обитаемость типа -- задача сводится к доказательству (проверки
  доказуемости) в ИИВ, факт разрешимости известен (TODO приложить
  пруф).
** Унификация
   Будем рассматривать термы следующей грамматики:

   A := T = T
   T := V | F([T]), где V -- это какая-то переменная, а F -- функция
   положительной арности.

   Выражение типа x = f(x, g(y)) подходит под нашу грамматику. Будем
   рассматривать систему таких равенств.

   * Подстановка S -- замена переменных, применяется достаточно
     прямолинейно:

     Если S(a) = b, то
     S(a) = b
     S(c) = c
     S(f(a, b, c,...)) = f(S(a), S(b), S(c),...)
   * Если S, T -- подстановки, то S∘T(x) = S(T(x)).
   * S разрешает систему уравнений если для каждого уравнения S(θᵢ) = S(μᵢ)
   * Система находится в разрешенной форме, если:
     1. xᵢ = θᵢ
     2. Если есть xᵢ=θᵢ, то нет j | xⱼ входит в θⱼ.
     3. Нет j ≠ i, что xᵢ = xⱼ
   * Система несовместна если
     1. ∀n, m  f(x₁...xₙ) = g(y₁...yₘ)
     2. x = f(..., x, ...)
   * Определение: S ⊆ T если ∃R | S = R∘T.
   * T -- наиболее общая подстановка, если для любого другого решения
     Q ⊆ T.

   * Теорема: aлгоритм унификации:

     Последовательное применение следующих правил к первому
     подходящему терму в системе приводят ее в разрешенную форму или
     показывают ее несовместность.

     Примечание: алгоритм подразумевает, что функции с одинаковым
     именем имеют одинаковую арность.

     Редукция терма это преобразование одного равенства в n:
     f(x₁...xₙ) = f(y₁...yₙ) ⇒ x₁=y₁; x₂ = y₂; ...

     Устранение переменной -- это замена во всех выражениях кроме
     выделенного x = t, где x переменная, а t ≠ x, x встречается
     где-то еще в системе, x на t, без удаления самого x = t.

     Алгоритм: Применять следующие правила по очереди для каждого
     терма в системе. Если какой-то терм показывает несовместность
     системы, остановиться. Если невозможно применить правило, система
     находится в разрешенной форме.
     1. t = x, где t не переменная, а x переменная ⇒ x = t
     2. x = x  ⇒ ()
     3. t' = t'', где t' и t'' не переменные ⇒ Если функции разные то
        система несоввместна, иначе применить редукцию терма.
     4. x = t, x переменная, t ≠ x, x встречается в системе где-то
        еще. Если x ∈ t, система несовместна, иначе применить
        устранение переменной.

     Доказательство того, что алгоритм завершается:

     Определим функцию F, отображающую набор равенств S в тройку
     натуральных чисел (n₁, n₂, n₃). n₁ -- количество свободных
     перменных в левых частях неравенств, которые встречаются больше
     одного раза. n₂ -- количество функциональных символов в S. n₃ --
     количество равенств типa x=x и t=x, где x-переменная, а t --
     нет.

     Определим линейный порядок на этих тройках:

     (n₁', n₂', n₃') > (n₁'', n₂'', n₃'') если

     1. n₁' > n₁'' или
     2. n₁' = n₁'' и n₂' > n₂'' или
     3. n₁' = n₁'' и n₂' = n₂'' и n₃' > n₃''

     Тогда N³ фундировано, то есть не существует бесконечно
     уменьшающейся цепочки таких троек. 1 и 2 операции уменьшают n₃,
     инодга n₁. 3 операция увеличивает n₃, уменьшая n₁ и точно
     уменьшая n₂. 4 может изменить n₃ или увеличить n₂, но уменьшает
     n₁.

     Насчет того, что унификация делает то, что надо, рассуждения
     похожие. Пусть алгоритм заканчивается неудачно, тогда система
     точно находится в неразрешенной форме. Если же алгоритм
     заканчивается успешно, то система находится в разрешенной форме
     ровно по определению.
** Вывод типа с помощью унификации
   Научимся теперь генерировать систему уравнений, резрешимость
   которой выдаст нам тип нужного выражения.

   Сопоставим каждому терму пару из набора уравнений на типах и одного
   выделенного типа этого терма.

   M → {Eₘ, τₘ}, αₓ - тип для x из М
   M ≡ x    ⇒ Em = ∅,
              τₘ = αₓ
   M ≡ PS   ⇒ α -- свежий тип, Eₘ = Eₚ ∪ Eₛ ∪ {τₚ = τₛ → α};
              τₘ = α
   M ≡ λx.P ⇒ Eₘ = Eₚ,
              τₘ = αₓ → τₚ

   * Теорема о валидности решения
     1. M -- терм, S -- решение Eₘ,
        Γ = {x:S(αx), x ∈ FV(M)}
        Тогда Γ ⊢ M S(τₘ)
     2. Γ ⊢ M:ρ, тогда найдется S -- решение Eₘ, что ρ=S(τₘ) и
        x:S(αx)∈Γ если x ∈ FV(M).

     Без доказательства, но в общем случае по индукции.
   * Определение. (Γ, τ) -- наиболее общий тип.
     1. Γ ⊢ M:τ
     2. ∀Γ' ≠ Γ, τ' ≠ τ, если Γ' ⊢ M:τ', то найдется S: Γ' = S(Γ), τ' = S(τ)у
   * Теорема об общности решения
     ({x: S(αx), x ∈ FV(M)}, τₘ) -- наиболее общий тип.
* Ticket 5   SN, models
** Нормализация, SN, импликация, насыщенность
   Определим понятие нормализации:
   1. Терм M слабо нормализуем, если существует хотя бы одна цепочка
      редукций, что M →→β Mnf, где Mnf -- нормальная форма M.
   2. Терм M сильно нормализуем, если любая цепочка редукций приводит
      к нормальной форме.

   * Замечание: слабо нормализуемые термы не типизируются в λ→.
   * Замечание: нормальный порядок редукции всегда приводит даже слабо
     нормализуемые термы в нормальную форму.

   Множество SN (сильно нормализуемые термы):
   1. Mσ -- нормальная форма, то M ∈ SN
   2. Если у M любой M' : M →β M' ∈ SN, то M ∈ SN

   Очевидным образом доказывается, что x ∈ SN ⇒ x сильно нормализуем.

   Определим операцию импликации на множествах термов:

   A → B = {C ∈ Λ | ∀P ∈ A, (C P) ∈ B}

   Тогда:
   [atomic_type] = SN
   [ρ → τ]       = [ρ] → [τ] (импликация на мн-вах)

   Будем называть множество X насыщенным, если:
   1. X ⊆ SN
   2. M₁...Mₙ ∈ SN ⇒ (..(x M₁) M₂) ... Mₙ) ∈ X
   3. P[x:=M₁]M₂...Mₙ ∈ X ⇒ (λx.P)M₁...Mₙ ∈ X, где P ∈ Λ, M₁..Mₙ ∈ SN

   Думать (наверное) надо так: насыщенное множество -- это
   подмножество SN из которого нельзя выйти путем 2 и 3 операций.
** Лемма о насыщенности
   1. SN насыщенно.

      1 свойство очевидно, 3 тоже.

      2 докажем от противного: пусть в x M₁ M₂ ...Mₙ есть цепочка
      редукций, не приводящая к NF, тогда она зацикливается. Значит
      какой-то Mⱼ содержит какой-то зацикливающийся кусок →←.
   2. A, B насыщено ⇒ A → B насыщено.
      1. Пусть A → B ∉ SN.

         Тогда посмотрим на зацикливающуюся цепочку редукций a₁ → a₂ →
         ...

         По определению → возьмем P ∈ A, тогда aⱼP ∈ B, ну раз так, то
         и a₁P → a₂P → ..., то есть мы получили, что B ∉ SN, что
         неверно по условию.
      2. Пусть M₁..Mₙ ∈ SN.

         Хотим доказать что x M₁ M₂ .. Mₙ ∈ A → B.

         Заметим, что поскольку A и B насыщены, x M₁ ... Mₙ ∈ A, ∈ B.

         Рассмотрим P ∈ A, P ∈ SN, тогда (a M₁ ... Mₙ P) ∈ B потому
         что для B тоже выполняется 2 свойство.
      3. C = P[x:=M₁] M₂ M₃ ... Mₙ ∈ A → B.

         По 3 правилу для B ∀Q∈A (λx.P)M₁...MₙQ ∈ B, тогда по
         определению '→' (λx.P)M₁....Mₙ ∈ A→B, что и требовалось
         доказать.
   3. σ - тип ⇒ [σ] насыщен.

      Доказательство очевидно, если внимательно посмотреть на пункт 1
      леммы и пункт 1 определения [t], и аналогично со 2 пунктами. По
      индукции по структуре типа.
** Оценка терма, ⊨
   Определим оценку терма. Пусть у нас есть функция оценки переменных
   в термы ρ: V → Λ, тогда определим замену в этой оценке:

   ρ[x:=N](x) = N
   ρ[x:=N](y) = ρ(y)

   1. ρ[x:=N]:V → Λ
   2. [M]ρ = M[x₁:=ρ(x₁), ...], где x₁...xₙ ∈ FV(M).

      Примечание: тут имеется в виду нижний индекс (ρ).
   3. ρ ⊨ M:σ, если [M]ρ ∈ [σ]  (оценка терма принадлежит типо-множеству)
   4. ρ ⊨ Γ, где Γ={x₁:γ₁, ...} если ρ(xᵢ) ∈ [γᵢ]
   5. Γ ⊨ M:σ, если (ρ ⊨ Γ ⇒ ρ ⊨ M:σ) -- честная булева импликация
** Теорема о коректности: Γ ⊢ M:σ ⇒ Γ ⊨ M:σ
   Традиционно, индукция по структуре вывода M.
   1. () ⟶ Γ', x:σ ⊢ x:σ

      Покажем, что ρ ⊨ Γ ⇒ ρ ⊨ x:σ. [x]ρ = ρ(x) ∈ [σ] немедленно из
      определения ρ ⊨ Γ.
   2. Γ ⊢ M:σ→τ; Γ ⊢ N:σ ⟶ Γ ⊢ (M N):τ

      ρ ⊨ Γ верно по индуктивному предположению. По предположению
      индукции Γ ⊨ M:σ → τ, Γ ⊨ N:σ.

      [M]ρ ∈ [σ] → [τ]; [N]ρ ∈ [σ] по индукционному предположению.
      [MN]ρ = [M]ρ [N]ρ ∈ [τ] по определению стрелки для [M]ρ.

      Что есть ровно ρ ⊨ MN:τ
   3. Γ,x:σ ⊢ M:τ        ⟶ Г ⊢ λx.M: σ → τ

      По индуктивному предположению:
      1. ρ ⊨ Γ
      2. Пусть N ∈ [σ], тогда ρ[x:=N] ⊨ Γ, x:σ.
      3. ρ[x:=N] ⊨ M:τ

      Из третьего следует, что [M]_{ρ[x:=N]} ∈ [τ].

      Мы хотим показать, что [λx.M]ρ ∈ [σ] → [τ].

      По определению стрелочки [λx.M]ρ N ∈ [τ].

      Это легко сделать:
      [λx.M]ρ N = (λx.M)[x₁:=ρ(x₁)...] N →β M[x:=N, x₁ = ρ(x₁), ...] =
      M_{ρ[x:=N]} ∈ [τ] что показано выше.
** Теорема: A ∈ Λ ⇒ A ∈ SN
    Если A ∈ Λ, то Γ ⊢ A:σ, отсюда по корректности Γ ⊨ A:σ, что есть
    ровно ρ ⊨ Γ ⇒ ρ ⊨ A:σ.

    Рассмотрим два случая относительно ρ:
    1. ρ ⊨ Γ

       Возьмем x:σ ∈ Γ и убедимся, что ρ(x) ∈ [σ]. Для этого
       достаточно взять ρ = id, то есть ρ(x) = x. По лемме о
       насыщенности пункт 3 поймем, что σ насыщено, потому что тип,
       тогда по 2 пункту определения насыщенности x ∈ [σ].
    2. Поскольку мы знаем, что ρ ⊨ Γ ⇒ ρ ⊨ A:σ выполняется, и первая
       часть импликации верна, то верна и вторая. Отсюда ρ ⊨ A:σ. По
       определению [A]ρ ∈ [σ], но [σ] насыщена как тип, и по 1 пункту
       леммы о насыщенности [σ] ∈ SN. Тогда с помощью ρ = id: A = [A]ρ
       ∈ [σ] ∈ SN.
* Ticket 6   Functions' representativity in λ→ (extended polynoms)
  Обозначим n~ как n-тый черчевский нумерал.

  h(x) - сложность типа x == количество стрелочек.
  h(α) = 0; h(σ → τ) = h(σ) + h(τ) + 1.

  * Лемма о глубине подтерма.
    N:τ - выражение в нормальной форме. S:σ - подвыражение N, причем S
    ≠ N и S ≠ x для всех свободных переменных x терма N.

    Тогда ∀σ ∃R:ρ - подвыражение N, что h(σ) < h(ρ).

    Рассмотрим, чем может быть подтерм S:
    1. S = y - связанная переменная. Найдем ту лямбду, которая
       связывает эту переменную: (λy:σ.N(y)):σ → τ =: R. R подходит
       под условия.
    2. S = RP, R : τ → σ для какого-то τ.
    3. S = λy.T ≠ N, тогда S -- часть выражения:
       1. R = (λa.S):α → σ
       2. SQ -- невозможный вариант, так как тогда N не нормальная
          форма.
       3. RS, тогда R: σ → α

  * Лемма. (λt.gⁿt)ᵐx →→β gᵐⁿx
    Индукция по m.
    1. m = 0 ⇒ (λt.gⁿt)⁰x = x = g⁰x
    2. Переход. Пусть (λt.gⁿt)ᵐx →→β g⁰x.

       (λt.gⁿt)ᵐ⁺¹x = (λt.gⁿt)((λt.gⁿt)ᵐ x) →→β gᵐⁿ ((λt.gⁿt)ᵐ x) →→β gᵐⁿ(gⁿ x) = g⁽ᵐ⁺¹⁾ⁿ x

  Будем называть расширенным полиномом следующее:
  E(x, y) = P₁(x, y)
  E(x, 0) = P₂(x)
  E(0, y) = P₃(y)
  E(0, 0) = k

  * Теорема о расширенных полиномах.

    ν = (α → α) → (α → α) -- тип некоторого нумерала.

    R : ν → ν → ν -- функция на двух натуральных числах, замкнутый
    лямбда-терм.

    ∀R найдется E(x, y), что R x~ y~ = E(x, y)~. Проще говоря, любое
    вычисление ограничено расширенным полиномом.

    Доказательство:

    Возмем (R a:ν b:ν) и вычислим: (R a b) (f:α→α) →→β N, где N в
    нормальной форме (такое всегда можно найти в силу типизируемости
    R).

    Рассмотрим подтерм T:τ. Он должен иметь тип либо ν, либо α → α,
    либо α. Доказательство этого по индукции далее. Более того, в N не
    может быть выражений типа не α, так как запрещены свободные
    переменные.
    1. h(τ) ≥ 3. Тогда T = a~ или T = b~. Пусть это не так, тогда
       существуют некоторые P:π, что P ≠ a, P ≠ b, h(π) ≥ 3. Возьмем P
       с наиболее глубоким типом, но тогда по лемме мы можем найти
       терм с более глубоким типом, а у a, b, f сложность ≤ 3. a~ и b~
       -- это свободные переменные, какими бы нумералами они не были,
       и поэтому не подпадают под действие леммы. Пока не думаем о них
       как о нумералах, пусть они просто переменные. Таким образом, мы
       бдуем усложнять тип подтерма до бесконечности. →←.
    2. h(τ) = 2. τ = (α → α) → α или α → (α → α)

       По лемме найдется S:σ, что σ = τ → ρ или σ = ρ → τ. В любом из
       случаев не найдется ρ, что ν=σ, то есть S≠a, S≠b, что
       невозможно по предыдущему пункту. С какой стороны не пририсуй
       стрелочку, все равно не получится переменная.
    3. h(τ) = 1 или h(τ) = 0. τ = α → α или τ = α

    Рассмотрим терм T:α → α, S -- подтерм N. Он может иметь форму (из
    очевидных соображений):
    1. T = f
    2. T = a S или b S , где S:α → α
    3. T = λy.S₁(S₂(...(Sₙ(z))..)), где Sᵢ - либо f, либо a f,
       либо b f, а z - переменная либо равная y, либо совсем другая.

    Покажем, что T[a:=x~, b=y~] =β λy.(f^{P(x, y)} y) или T =β λy.f^{P(x, y)} z.

    P(x, y) -- это натуральное число, в данном контексте выступающее в
    качестве степени f, что есть количество применений f к
    себе. Первое -- это честное примение, второе -- константа. Будем
    использовать индукцию по структуре.
    1. T ≡ f, тогда E(m, n) = 1 и T = f¹
    2. T ≡ a T (b T аналогично), тогда:
       1. Пусть S=λx.f^{E(m, n)~} x, тогда
          a[a:=m~] S = (λf.λx.fᵐ x)(λx.f^{E(m, n)~} x) →β (λx.(λx.f^{E} x)ᵐ x) →→β по лемме λx.(f^(E(m, n)~))ᵐ x ≡ λx.f^(E(m, n)~) x  (последний шаг -- E * const = E).
       2. Пусть S=λx.f^{E(m, n)~} z, тогда
          аналогично a[a:=m~] S = (λf.λx.fᵐx)(λx.f^{E(m,n)~} z) →→β λx.(\x.fᴱ z)ᵐ x →→β по лемме λx.fᴱ z
    3. T ≡ λy.S₁(...(Sₙ z).)

       Sⱼ = λp.fᴱ p или λp.fᴾ z.

       Тогда если z = y и все Sⱼ имеют тип λp.fᴱ p, то мы протащим это
       y вверх.

       Если хотя бы один Sⱼ имеет тип λp.fᴱ z или z ≠ y, то константа.
* Ticket 7   Intuitionistic logic 2, Kripke models
  В ИИВ второго порядка грамматика такая:

  2Φ = ⊥ | p | 2Φ → 2Φ | 2Φ ∨ 2Φ | 2Φ ∧ 2Φ | ∀p.2Φ | ∃p.2Φ, где p ∈ PV
  -- набор пропозициональных переменных.

  Правила для кванторов:
  Γ ⊢ φ              ⟶ Γ ⊢ ∀p.φ           p ∉FV(Γ)
  Γ ⊢ ∀p.φ           ⟶ Γ ⊢ φ[p:=σ]
  Γ ⊢ φ[p:=σ]        ⟶ Γ ⊢ ∃p.φ
  Γ ⊢ ∃p.φ; Γ,φ ⊢ ψ  ⟶ Γ ⊢ ψ              p ∉FV(Γ, ψ)

  * В Φ2 невозможно в общем виде установить факт доказуемости формулы.
** Алгебры Гейтинга
   Напомним определения теории алгебр:
   * Фундированное мн-во -- частично упорядоч. множество, в котором
     каждое непустое подмножество имеет минимальный элемент.
   * Псевдобулева алгебра (алгебра Гейтинга) -- это импликативная (а
     значит и дистрибутивная) решетка над фундированным множеством с
     ¬a = (a → 0).
   * Псевдобулева алгебра -- <L, ≤, ∩, ∪, ¬, 0, 1> + аксиомы:
     ассоциативность×2, коммутативность×2, законы поглощения×2,
     дистрибутивность×2, дополнительность (только одна -- a ∧ ¬a =
     0). Тогда a → b = max c | c * a ≤ b.

   Пусть v:V → H -- оценка, из набора пропозициональных переменных в
   алгебру Гейтинга.

   Расширим v на все формулы и связки из Φ2 следующим образом:
   v(φ ∨ ψ) = v(φ) ∪ v(ψ)
   v(φ ∧ ψ) = v(φ) ∩ v(ψ)
   v(φ → ψ) = v(φ) → v(ψ)
   v(⊥)     = 0
   v(∀p.φ)  = inf{vₚᵃ(φ): a ∈ H}
   v(∃p.φ)  = sup{vₚᵃ(φ): a ∈ H}
   где vₚᵃ -- оценка, определяемая следующим образом:
   vₚᵃ(p) = a
   vₚᵃ(q) = v(q)

   Выражение T является тавтологией (⊨ T), если для любой оценки
   переменных v, для любой полной алгебры Гейтинга v(T) = 1.

   * Теорема. Φ2 полно и корректно отнсительно алгебр Гейтинга.
     Доказательство опущено.
** Модели Крипке
   * Моделью Крипке для Φ2 является тройка <C, ≤, {Dc:c∈C}>, где C --
     непустое множество, ≤ -- частичный порядок на нем, А Dc --
     замкнутые вверх множества (∀c, c', c ≤ c', c∈D ⇒ c'∈D).
   * Оценка v отображает пропозициональные переменные в поддеревья
     C. Оценка называется допустимой для мира c тогда и только когда
     ∀p -- пропозициональных переменных v(p) ∈ Dc. По замкнутости
     вверх если оценка допустима в c, то она допустима во всех мирах
     больше c.
   * v{p;x} -- оценка v, что v{p;x}(p) = x, v{p;x}(q) = v(q).
   * Отношение вынужденности ⊩:

     Есть идея насчет того, что значит оценка -- это раскидываение
     переменных по поддеревьям.

     * c,v ⊩ p         iff  c∈v(p)
     * c,v ⊩ φ ∨ ψ     iff  c,v ⊩ φ or c,v ⊩ ψ
     * c,v ⊩ φ ∧ ψ     iff  c,v ⊩ φ and c,v ⊩ ψ
     * c,v ⊩ φ → ψ     iff  для всех c'≥ c  выполнено c',v ⊩ φ ⇒ c',v ⊩ ψ
     * c,v ⊩ ⊥         не выполнено в каком-либо мире
     * c,v ⊩ ∃p.φ      iff c,v{p;x} ⊩ φ для какого-либо x ∈ Dc -- то есть
       мы можем найти такое поддерево нашего мира что если в нем
       вынудить p, то будет вынуждено φ
     * c,v ⊩ ∀p.φ      iff  c',v{p;x} ⊩ φ для всех c'≥c и всех x ∈ Dc'
       в любом поддереве в котором можно положить нашу переменную, будет вынуждено φ.

   * Модель Крипке полна, если для каждой формулы φ, каждого мира c и
     каждой оценки v множество v(φ)={c' | c',v ⊩ φ} ∈ Dc когда v
     допустимо в c.
   * Γ ⊩ φ тогда и только когда для каждой полной модели крипке C
     каждой модели c и каждой оценки v допустимой для c такой что c,v
     вынуждает все формулы из Γ, также верно c,v ⊩ φ.

   * Теорема
     Φ2 полно относительно моделей Крипке.
** Доказательство базисности {→, ∀}
   В Φ2 возможно выразить все связки только через {→, ∀}.
   * Выразимость ∧
     ∧ = ∀R((A → B → R) → R)
     1. Давайте покажем Γ ⊢ A∧B ⟶ Γ ⊢ A
        Γ ⊢ ∀R((A→B→R)→R)  ⟶
        Γ ⊢ (A→B→A)→A      ⟶        первая часть -- аксиома, работает в предикатах 1 порядка
        Γ ⊢ A
        B доказывается аналогично
     2. Покажем Γ ⊢ A; Γ ⊢ B   ⟶ Γ ⊢ A ∧ B
        Γ' := Γ, A→B→R
        Γ' ⊢ A→B→R; Γ' ⊢ A  ⟶
        Γ' ⊢ B→R; Γ' ⊢ B    ⟶
        Γ' ⊢ R              ⟶
        Γ ⊢ (A→B→R)→R
   * Выразимость ∨
     A ∨ B = ∀R.(A → R) → (B → R) → R
     1. Докажем, что Γ ⊢ A ⟶ Γ ⊢ A ∨ B
        Γ, A→R, B→R ⊢ A→R; Γ ⊢ A  ⟶
        Γ, A→R, B→R ⊢ R
        Γ, A→R ⊢ (B→R)→R
        Γ ⊢ (A→R)→(B→R)→R
        Γ ⊢ ∀R((A→R)→(B→R)→R)
     2. Докажем, что Γ ⊢ A∨B; Γ,A ⊢ P; Γ,B ⊢ P ⟶ Γ ⊢ P
        Γ ⊢ ∀R((A→R)→(B→R)→R)      ⟶
        Γ ⊢ (A→P)→(B→P)→P; Γ ⊢ A→P ⟶
        Γ ⊢ (B→P)→P; Γ ⊢ B→P       ⟶
        Γ ⊢ P
   * Выразимость ∃
     ∃X = ∀R.(∀X.(A → R) → R)
     Эта формула передает двойное отрицание, что имеет смысл: (∀X.A = ¬∃X(¬A))
     * Докажем, что Γ ⊢ A[P:=S] ⟶ Γ ⊢ ∃P.A
       Γ' = Г, ∀P.(A→B), пусть в B нету S
       Γ' ⊢ ∀P.(A→B)                   ⟶
       Γ' ⊢ A[P:=S]→B, Γ' ⊢ A[P:=S]    ⟶
       Γ' ⊢ B;
       Γ  ⊢ ∀P.(A→B)→B
       Γ  ⊢ ∀R.(∀P.(A→R)→R)
     * Докажем, что Γ ⊢ ∃P.A; Γ, A ⊢ N ⟶ Γ ⊢ N
       Γ ⊢ ∀X.(A → N) → N             (из первого снятием квантора)
       Γ, A ⊢ N              ⟶
       Γ ⊢ A → N             ⟶
       Γ ⊢ ∀X.(A → N)
       Вместе с первым утверждением по MP
       Γ ⊢ N
   * Выразимость ⊥
     ⊥ = ∀A.A
     v(∀p.φ)  = inf{vₚᵃ(φ): a ∈ H}
     Тогда v(∀p.p) = inf{νₚᵃ(p): a∈H} = 0 (для любой оценки оно отображает в a).
     в силу полноты алгебры Гейтинга, все ок.
* Ticket 8   System F, C-H, pairs/existential types
** Определения системы F
   System F -- система, изоморфная Φ2. Пусть α, x -- атомарный тип и
   переменная соответственно. Грамматики такие:

   Π = α | Π → Π | ∀α.Π
   T = x | T T | ∀x:σ.T | Λα.T | L Π   (тут по Чёрчу)

   Аксиомы:
   ()                 ⟶ Γ,x:σ ⊢ x:σ        x ∉ Γ
   Γ ⊢ M:τ→σ; Γ ⊢ N:τ ⟶ Γ ⊢ MN:σ
   Γ, x:σ ⊢ M:τ       ⟶ Γ ⊢ λx.M:σ→τ       x ∉ Γ
   Γ ⊢ M:σ            ⟶ Γ ⊢ Λα.M:∀p.φ      p ∉ FV(Γ)
   Γ ⊢ M:∀α.σ         ⟶ Γ ⊢ Mτ:σ[α:=τ]
** Алгебраические типы
   За доказательство обращаться в предыдущую главу 7, последний
   пункт. TODO переписать сюда с лямбдами, если будет время.

   * Булева логика и нумералы
     Bool = ∀α(α → α → α)
     T = Λα.λx:α.λy:α.x
     F = Λα.λx:α.λy:α.y
     Not = λx:Bool.(x Bool)
     Int = ∀α.(α → α) → α → α
     n~ = Λα.λf:α→α.λx:α.fⁿx
     и так далее.
   * Пары и case'ы
     1. a ∨ b = ∀p.((a → p) → (b → p) → p)
        Γ ⊢ M:φ  ⟶ Γ ⊢ inl(M):φ ∨ ψ
        Γ ⊢ M:ψ  ⟶ Γ ⊢ inr(M):φ ∨ ψ
        Γ ⊢ L:φ ∨ ψ; Γ,x:φ ⊢ M:ρ; Γ,y:ψ ⊢ N:ρ ⟶ Γ ⊢ case(L,x,M,y,N):ρ
        inl = λm:φ.Λα.λf:φ→α.λg:ψ→α.f m
        inr = λm:ψ.Λα.λf:φ→α.λg:ψ→α.g m
        case = λpair:φ∨ψ.λf:φ→ρ.λg:ψ→ρ.pair ρ f g
     2. <a,b> = ∀p.((a → b → p) → p)
        Γ ⊢ a:α; Γ ⊢ b:β ⟶ Γ ⊢ pair:<α,β>
        Γ ⊢ M:<α,β>      ⟶ Γ ⊢ π₁:<α,β> → α
        Γ ⊢ M:<α,β>      ⟶ Γ ⊢ π₂:<α,β> → β
        pair: Λσ.λz:α→β→σ.z a b
        π₁ = λpair:<α,β>.pair α True
        π₁ = λpair:<α,β>.pair β False
   * Экзистенциальные типы
     ∃x.a  = ∀p.(∀x.(a → p) → p)
     Γ ⊢ M:σ[α:=τ]            ⟶ Γ ⊢ (pack M,τ to ∃α.σ) : ∃α.σ
     Γ ⊢ M:∃α.σ; Γ, x:σ ⊢ N:ρ ⟶ Γ ⊢ (abstype α with x:σ is M in N) : σ
     (pack M,τ to ∃α.σ) = Λβ.λx:∀α.(σ→β).(x τ) M
     (abstype α with x:σ is M in N) = M ρ (Λα.λx:σ.N)
     В качестве примера можно привести интерфейсы из джавы которые
     очень близки по смыслу к экзистенциальным типам. Т.е.
     List<Integer> list = new ArrayList<>() как раз и стирает наше
     знание о том какой же тип это на самом деле был изначально.
** Леммы о системе F
   1. Система F сильно нормализуема, то есть любое типизируемое
      утверждение ∈ SN.
   2. Subject reduction: если Γ ⊢ t:τ и t →→β t', то Γ ⊢ t':τ
   3. Γ ⊢ M:? неразрешимо (алгоритм реконструкции типа неразрешим).

      Задача унификация первого порядка: f a = f b ⇒ a = b. Есть еще
      унификация второго порядка: g a = f a. Чтобы доказать, что
      система F не имеет алгоритма для вывода типов, сделаем
      следующее (5 семестр КТ, теория формальных языков -- там
      пояснят за неразрешимость):

      DISCLAIMER:
      Дальше написано что-то в корне неправильное. Мы свели нашу задачу
      к задаче останова. Молодцы. Вот только ничего это не доказывает.

      1. Сведем задачу к унификации второго порядка.
      2. Унификацию к машине тьюринга с двумя стеками, которая
         эквивалентна 4м счетчикам, которая эквивалентна двум
         счетчикам.

         [[http://neerc.ifmo.ru/wiki/index.php?title=Счетчиковые_машины,_эквивалентность_двухсчетчиковой_машины_МТ][Вот тут поясняют.]]
      3. Потом сводим к задаче останова.
   4. Изоморфизм Карри-Ховарда.

      Система F изоморфна Φ2, то есть:
      Γ ⊢ A:σ       ⇒ types(Γ) ⊢* σ
      {τ₁..τₙ} ⊢* σ  ⇒ ∃A,{xₙ}, что {xⱼ:τⱼ} ⊢ A:σ

      Теорема Карри-Ховарда для системы F не нужно доказывать.
   5. Изо/эквирекурсивные типы.

      hd :: [a] → a
      hd x = match x with
             [] → tail
             x:xs → x

      Получается такая странная вещь, что например cons :: a list → a
      → a list. Если мы выпишем лямбда-выражение соответствующее этому
      типу, то типизация сломается:

      cons a b ≠ list, потому что <list a, a> != list a.

      Это рекурсивный тип, который мы хотим сохранить, несмотря на
      рекурсию.

      Существует два подхода к проблеме разрешимости рекурсивных
      типов: эквирекурсивный и изорекурсивный.

      Пусть у нас есть тип μa.T -- такой тип, что мы хотим рассматривать и T[μa.T] и T[a].
      Изорекурсивный подход -- установление изоморфизм типа list a ~ a
      & list a с помощью двух симметричных функций: roll и unroll. При
      этом μa.T ≠ T[μa.T ∨ a].

      roll:   T[μa.T ∨ a] → μa.T
      unroll: μa.T → T[μa.T ∨ a]

      В С это указатель, потому что мы можем превращать struct в
      <pointer struct>, они изоморфны. То есть мы имеем явную
      реализацию преобрзования, и мы ее применяем, чтобы у нас тип
      функции остался List → List. В теле функции мы подняли тип,
      получили какое-нибудь a & a & a... , поработали с ним, а в конце
      опустили. Так в хаскеле делают.

      Эквирекурсивный подход: будем думать о μa.T и о T[μa.T ∨ a]
      одновременно как об одном и том же. μlist.a&list -- это тип
      решающий выражения типа a & list = list, то есть эквирекурсивный
      тип, оно типа решает уравнение с фиксированной точкой. Так в
      джавке делают. В джавке вон например Enum<E extends Enum<E>>,
      вот тут оно и используется.
* Ticket 9   Hindley-Milner, W algorithm
** Аксиоматизация
   Грамматика на термах (Λₗₑₜ):

   Λₗₑₜ = x | Λₗₑₜ Λₗₑₜ | λx.Λₗₑₜ | let x = Λₗₑₜ in Λₗₑₜ
   τ = α | τ → τ -- тип (монотип)
   σ = ∀a.σ | τ  -- типовая схема (политип)

   Важное отличие от системы f -- кванторы на типах могут быть только
   внешние.

   Специализация:

   σ' ≤ σ, если σ = ∀a₁..aₙ.τ, σ' = ∀b₁...bₘ.τ[aᵢ=θᵢ].

   Наивное понимание -- меньший тип -- более специфический, у него
   меньше кванторов.

   Добавим синтаксического сахара: Если A -- контекст, а x --
   переменая, то Aₓ = {(s:θ) | (s, θ)∈A, s≠x}.

   Правила (внимательно следить за различием между σ и τ):
   1. Существование: ()                ⟶ A, x:σ ⊢ x:σ
   2. Обобщение:     A ⊢ e:σ           ⟶ A ⊢ e: ∀α.σ       e ∉ FV(A) в посылках
   3. Инстанциация:  A ⊢ e:σ           ⟶ A ⊢ e:σ'          σ' ≤ σ
   4. A ⊢ e:τ'→τ;  A ⊢ e':τ'           ⟶ A ⊢ ee':τ
   5. Aₓ, x:τ' ⊢ e:τ                   ⟶ A ⊢ (λx.e):τ'→τ
   6. A ⊢ e:σ;  Aₓ, x:σ ⊢ e':τ         ⟶ A ⊢ (let x=e in e'):τ
   7. Fix: ()                          ⟶ A ⊢ fix:∀α((α → α) → α)

   Последнее правило помогает нам делать рекурсивные функции. И вообще
   это частая практика добавить к аксиомам некоторое fix-правило, если
   чего-то не хватает. И это Y-комбинатор.

   (λf.<f T, f 0>) id -- не типизируется в Х-М, потому что id имеет
   простой тип
** Пример неполноценности Х-M
   Есть хорошая аналогия.

   Есть лохи, Клини вот и Чёрч неправы, потому что не сошли с
   ума. Потому что число нужно записывать в Пеано. Но числа нужно
   записывать в двоичной системе, так же удобнее. Люди, которые делают
   список из Пеано,

   Список -- это число, которое говорит, о своей длине. Если он
   говорит о ней как о количестве единичек, то это плохой
   список. Вместо этого мы будем говорить о честных бинарных списках.

   Нолик означает, что происходит удвоение следующего
   разряда. Единичка -- удвоение следующего разряда и еще что-то от
   нас.

   Тогда если у нас есть некий элемент списка, то это Nil, либо Zero
   BL (a,a) либо One a (BL (a, a)) -- типа умножаем на 2 и прибавляем
   себя.

   Таким образом, мы можем хранить любое множество в списке так, что
   структура списка говорит о его длине, но получать элементы мы будем
   всё ещё за O(N).
   Будем нумеровать двоичные последовательности списками:

   data T a = Nil | One a (T (a, a)) | Zero (T (a, a))

   Пример того, как нумеруются двоичные последовательности (читать
   термы нужно справа налево).
   |------------------------------------+-----|
   | One(1, Nil)                        |   1 |
   | Zero(One((1,2), Nil))              |  10 |
   | One(3, One((1,2), Nil))            |  11 |
   | Zero(Zero(One((1,2,3,4), Nil)))    | 100 |
   |------------------------------------+-----|

   Давайте напишем фукнцию append: a → T a → T a. Она добавляет к
   нашему списку элемент.

   append a Nil      = One(a, Nil)
   append a Zero(x)  = One(a, x)
   append a One(t,l) = Zero(append (a,t) l)

   Вот эта фукнция не типизируется в Х-М. В 3 пункте во внутреннем
   accept имеет тип пары (a, a), а внешний точно a. Отсюда будут
   существовать кванторы внутри, что не положено, потому что у нас
   политипы и монотипы.
** Вывод типов и алгоритм W
   Наивные соображения на тему, почему у нас в Х-М будет выводится
   тип, если в системе F нет:

   В системе F кванторы в типах где угодно, в Х-М только внешние. Плюс
   к этому, в существенных правилах 4, 5 используются монотипы, а не
   политипы.

   Задача типизации: A ⊢ e:?. Найдем такие S, τ, что S(A) ⊢ e:τ,
   причем подстановка наиболее общая.

   Пример: max: α → α → α ⊢ max [] : ?

   S(α) = [β] (заметим, что подстановка -- наиболее общая. Не какая-нибудь [Int])
   τ = [β] → [β]
   max: [β] → [β] → [β] ⊢ max [] : [β] → [β] применением.

   Будем называть U алгоритмом унификации, который для двух термов
   выдает подстановку.

   Если A -- контекст, то A~(τ) = ∀α₁...αₙ.τ, где αᵢ ∈ FV(A).

   Построим функцию W(A,e) = (S,τ).
   1. e = x₁ ∧ (x₁, ∀α₁...αₙ.τ') ∈ A
      ⇒ S = id, τ = τ'[αᵢ=βᵢ], где βᵢ -- новые типы.
   2. e = e₁e₂
      W(A, e₁) = (S₁, τ₁)
      W(S₁(A), e₂) = (S₂, τ₂)
      U(S₂(τ₁), τ₂ → β) = V, β -- новая переменная
      ⇒ S = VS₂S₁, τ = Vβ
   3. e = λx.e₁
      β -- новая переменная
      W(Aₓ∪{x:β}, e₁) = (S₁, τ₁)
      ⇒ S = S₁, τ = S₁β → τ₁
   4. e = let x=e₁ in e₂
      W(A, e₁) = (S₁, τ₁)
      W(S₁(Aₓ)∪{x:S₁(A)~(τ₁)}, e₂) = (S₂, τ₂)
      ⇒ S = S₂S₁, τ = τ₂

#   1. Существование: ()                ⟶ A, x:σ ⊢ x:σ
#   2. Обобщение:     A ⊢ e:σ           ⟶ A ⊢ e: ∀α.σ       e ∉ FV(A) в посылках
#   3. Инстанциация:  A ⊢ e:σ           ⟶ A ⊢ e:σ'          σ' ≤ σ
#   4. A ⊢ e:τ'→τ;  A ⊢ e':τ'           ⟶ A ⊢ ee':τ
#   5. Aₓ, x:τ' ⊢ e:τ                   ⟶ A ⊢ (λx.e):τ'→τ
#   6. A ⊢ e:σ;  Aₓ, x:σ ⊢ e':τ         ⟶ A ⊢ (let x=e in e'):τ
#   7. Fix: ()                          ⟶ A ⊢ fix:∀α((α → α) → α)

   * Лемма. Если A ⊢ e:σ, то SA ⊢ e:Sσ, причем второе доказательство
     имеет длину не больше первого.

     Рассмотрим структурную индукцию по e:
     1. e выведена из 1 правила.
        Отсюда:
        () ⟶ A, x:σ ⊢ x:σ
        () ⟶ SA, x:Sσ ⊢ x:Sσ
     2. e выведена из 2 правила.
        A ⊢ e:σ ⟶ A ⊢ e:∀α.σ
        Тогда и
        SA ⊢ e:Sσ ⟶ SA ⊢ e:S(∀α.σ)
     3. e выведена из 3 правила
        Аналогично
     4. SA ⊢ e:S(τ'→τ); SA ⊢ e':Sτ', тогда применим 4 правило, SA ⊢ ee':Sτ
     5. e выведена из 5 правила, тогда по 5 правилу тож
     6. 6 правило так же
   * Теорема: aлгоритм W работает корректно. Если W(A, e) завершается
     успешно с (S, τ), то существует вывод SA ⊢ e:τ.

     Будем доказывать структурной индукцией по e.
     1. e = x₁. Тогда мы могли вывести x₁ только по 1 правилу, значит
        подстановка нам не нужна, id сойдет. Если там не было
        кванторов, то все ок, по 1 правилу выведется. Если были, то
        по 3.
     2. e = e₁e₂. Тогда по индукции S₁A ⊢ e₁:τ₁, S₂(S₁A) ⊢ e₂:τ₂.

        Навесим на первое подстановку S₂: S₂S₁A ⊢ e₁:S₂(τ₁) по лемме.

        Теперь воспользуемся алгоритмом унификации, чтобы найти
        решающую подстановку V. Отсюда VS₂(τ₁) = V(τ₂) → V(β).

        Навесим на предыдущее и второе в первоначальном выводе
        подстановку V:

        VS₂S₁A ⊢ e₁:VS₂(τ₁); VS₂S₁A ⊢ e₂:V(τ₂). Заменим вывод в первом
        утверждении по унификации:

        VS₂S₁A ⊢ e₁:V(τ₂) → V(β); VS₂S₁A ⊢ e₂:V(τ₂) ⟶ VS₂S₁A ⊢ e₁e₂:V(β).
     3. e = λx.e₁, тогда по индукции S₁(Aₓ∪{x:β}) ⊢ e₁:τ₁. Что
        аналогично: S₁Aₓ, x:S₁β ⊢ e₁:τ₁. Теперь просто шмякнем аксиому
        о лямбде.

     4. e = let x=e₁ in e₂.

        По индукции:
        S₁A ⊢ e₁:τ₁;
        S₂(S₁(Aₓ)∪{x:S₁(A)~(τ)) ⊢ e₂:τ₂ = S₂S₁Aₓ, x:S₂(S₁(A)~ τ₁) ⊢ e₂:τ₂.

        Покажем, что S₂Γ ⊢ e₁:S₂τ₁ ⟶ S₂Γ ⊢ e₁:S₂(Γ~(τ₁)). То есть в
        нашем случае S₂S₁A ⊢ e₁:S₂τ₁ ⟶ S₂S₁A ⊢
        e₁:S₂(S₁(A)~(τ₁)). Много раз применим обобщение.

        Тогда по правилу для let подставим последнее первым
        аргументом, а вторую индукционную посылку первым, и получим
        то, что нужно.
* Ticket 10  Hindley-Milner type derivation (restrictions)
  Другой подход к выводу типов в системе Хиндли-Милнера --
  использование ограничений.

  T - базовый тип.
  σ = ∀X~[C].T -- типовая схема.

  Определим грамматику обобщенных ограничений:

  C,D = true | false | P T₁..Tₙ | C ∧ C | ∃X~.C | def x:σ in C | x ≼ τ

  Также существует дополнительный синтаксический сахар:
  1. Если σ = ∀X~[D].T и X~ ∈ FTV(T') то для констрейнта ∃X~(D ∧ T ≤
     T') выполнено σ ≼ T' и T' -- инстанс σ.
  2. Мы пишем ∃σ (у σ есть инстанс) для ∃X~.D
  3. let x:σ in C для обознгачения ∃σ∧def x:σ in C.
  4. def Γ in C -- это (если Γ = x₁:τ₁...) def x₁:τ₁ in def x₂:τ₂ in ... in C
  5. let Γ in C -- это let x₁:τ₁ in let .. in C
  6. ∃∅ = true, ∃(Γ,x:σ) = ∃Γ ∧ def Γ in ∃σ
  Есть такое ощущение, что let не нужен вообще в етой грамматике.

  Определим констрейнт контекст:
  ℂ = [] | C | ℂ ∧ ℂ | ∃X~.ℂ | def x:σ in ℂ | def x:∀X~[ℂ].T in C

  Определим функцию перехода от Х-М к грамматике ограничений (опять τ≠σ):
  [x:τ]    = x ≼ τ
  [λx.e:τ] = ∃α₁.∃α₂.(let x:α₁ in [e:α₂] ∧ α₁ → α₂ ≤ τ)
  [e₁e₂:τ]  = ∃α₂.([e₁:α₂→τ] ∧ [e₂:α₂])
  [let x=e₁ is e₂:τ] = let x:∀α([e₁:α]).α in [e₂:τ]

  Mₖ -- это базовый универсум всех типов кайнда k, тогда:
  * φ: A → M, A -- множество типов. A -- тип, тогда φ(T) -- базовый тип.
  * S базовая типовая схема -- набор базовых типов, который должен быть замкнут вверх относительно ≤.
  * ψ: V → {S}, V -- множество вещественых переменных

  Определим отношение удовлетворимости. Имеется в виду, что
  ограничение удовлятворяет (φ, ψ). Будем писать φ, ψ ⊪ C.

  * (φ, ψ)(∀X~[C].T) = ↑{φ[X~ ↦ t~](T); φ[X~ ↦ t~],ψ ⊨ C}
  * φ, ψ ⊨ true
  * P(φ(T₁)...φ(Tₙ))      ⟶ φ,ψ ⊨ P T₁ ... Tₙ
  * φ,ψ ⊨ C₁; φ,ψ ⊨ C₂   ⟶ φ,ψ ⊨ C₁ ∧ C₂
  * φ[X~ ↦ t~],ψ ⊨ C     ⟶ φ,ψ ⊨ ∃X~.C
  * φ,ψ[x ↦ (φ,ψ)σ] ⊨ C  ⟶ φ,ψ ⊨ def x:σ in C
  * φ(T) ∈ ψ(x)           ⟶ φ,ψ ⊨ x ≼ T
#  φ, ψ ⊨ τ₁ = τ₂        если   φ(τ₁) = φ(τ₂)
#  φ, ψ ⊨ A ∧ B         если   φ, ψ ⊨ A ∧ φ, ψ ⊨ B
#  φ, ψ ⊨ ∃α.C          если   ∃θ, что (φ,ψ)[α:=θ] ⊨ C
#  φ, ψ ⊨ def x:α in C  если
#  φ, ψ ⊨ x = τ         если   ψ(x) = φ(τ)
#  φ, ψ ⊨ x ≼ τ         если   φ(τ) ∈ ψ(x)
#  φ, ψ ⊨ let x:α in C  если   *???* Очень похоже на def, может его вообще в грамматике нету?

  C₁ ⊨ C₂ (одно влечет другое), если ∀ψ,φ  φ,ψ ⊨ C₁ ⇒ φ,ψ ⊨ C₂.

  Разрешенная форма это констрейнт вида ∃Y~.(X→ = T→), где X~ ∈ FV(T~)

  Теорема. каждый констрейнт эквивалентен разрешенной форме или false.

  Каноничная разрешенная форма -- ∃Y~.(X→ = T→), где FV(T~) ⊂ Y~ и X

  Существует алгоритм, который приводит констрейнт в разрешенную форму.
* Ticket 11  λ-cube
** Определения
   Очень хочется создать некоторую мета-классификацию над самыми
   модными типовыми системами, которую можно было бы параметризовать.

   S = {*, ■} -- набор сортов.

   Для каждого s ∈ S определим Vs -- счетное множество переменных,
   причем Vs ∩ Vs' = ∅, если s ≠ s'. V = ⋃{s}Vs.

   Грамматика для выражений в нашей системе такая:

   E = V | S | E E | λV:E.E | ΠV:E.E

   Наивное понимение Π -- это стрелочка на типах.

   Пусть аксиоматизация параметризована (s₁,s₂) ∈ S:
   1. Аксиома:    ()                                   ⟶ Γ ⊢ *:■
   2. Старт:      Γ ⊢ A:s                              ⟶ Γ,x:A ⊢ x:A
   3. Ослабление: Γ ⊢ A:B; Γ ⊢ C:S                     ⟶ Γ, x:C ⊢ A:B
   4. Применение: Γ ⊢ F:(Πx:A.B); Γ ⊢ a:A              ⟶ Γ ⊢ (F a):B[x:=a]
   5. Π-правило:  Γ ⊢ A:s₁; Γ, x:A ⊢ B:s₂               ⟶ Γ ⊢ (Πx:A.B):s₂
   6. λ-правило:  Γ ⊢ A:s₁; Γ, x:A ⊢ b:B; Γ, x:A ⊢ B:s₂ ⟶ Γ ⊢
      (λx:A.b):(Πx:A.B)

   Последние два правила представляют собой особую ценность и могут
   быть использованы отдельно для каждого набора (s₁, s₂), которым
   будет параметризована система.

   По Соренсену есть две поправки (может быть, это критично):
   1. λ-правило:  Γ, x:A ⊢ b:B; Γ ⊢ (Πx:A.B):s ⟶ Γ ⊢ (λx:A.b):(Πx:A.B)
   2. Конверсия:  Γ ⊢ A:B; Γ ⊢ B':s            ⟶ Γ ⊢ A:B'              если B =β B', где β-эквивалентность определяется наивно.

   Возьмем нашу систему с любым ненулевым набором аксиоматизаций из
   следующих вариантов: {(⋆, ⋆), (⋆, □), (□, ⋆), (□, □)}.
   |---------+--------+--------+--------+--------|
   | Система | (⋆, ⋆) | (□, ⋆) | (□, □) | (⋆, □) |
   |---------+--------+--------+--------+--------|
   | λ→      | ✓      |        |        |        |
   | λ2      | ✓      | ✓      |        |        |
   | λω_     | ✓      |        | ✓      |        |
   | λω=λω_2 | ✓      | ✓      | ✓      |        |
   | λP      | ✓      |        |        | ✓      |
   | λP2     | ✓      | ✓      |        | ✓      |
   | λPω_    | ✓      |        | ✓      | ✓      |
   | λC=λPω  | ✓      | ✓      | ✓      | ✓      |
   |---------+--------+--------+--------+--------|

   Обычно системы ставят в точки куба, тогда вот куб получается. В нем
   каждая ось задает включение некоторого из трех правил, не считая
   первого.
   1. (⋆, □) -- dependent types, типы зависят от значений.
   2. (□, ⋆) -- полиморфизм.
   3. (□, □) -- типовые операторы.

   Опишем немного системы:
   * λ→ -- обычный советский λ-calculus по Чёрчу или Карри.
   * λ2 = System F, можно делать функции из типов в значения
     (Λα.λx:α.x).
   * Хиндли-Милнер тут находится где-то около SystemF, но не входит
     формально.

     Типовая система Haskell разрешает фукнции из типов в значения, но
     там есть instance, и вообще все мутно. Тоже не классифицируется
     этим кубом.

     Update на 2016 год:
     https://ghc.haskell.org/trac/ghc/wiki/DependentHaskell

     И вообще есть TypeFamilies и DataFamilies. Конструкторы
     DataType'ов -- это функции из значений в типы.
   * Agda больше похожа на λC, потому что там в общем случае можно
     делать функции и из типов в термы, и наоборот, и из типов и типы.
** Примеры и леммы
   * Давайте выразим Maybe.

     Maybe = λα:*.()∨α
     ⊢ ⋆:■                ⟶
     α:⋆ ⊢ ()∨α:⋆;  ⊢ ⋆:■ ⟶
     ⊢ (λα:⋆.()∨α):Πα.*.*
     Все логично, Maybe:* → *
   * Ситуация с ложью

     В лямбда кубе, ввиду возможности писать функции на типах и
     выражениях, будет две лжи:

     ⊥ = Πx:*.x
     ⊥* = Πx:■.x
   * Теорема Чёрча-Россера

     A, B, B' -- выражения, A →→β B, A →→β B', тогда ∃C, что B →→β C,
     B' →→β C.

     A =β B, то ∃C  A →→β C ∧ B →→β C.
   * Обобщенное Subject reduction.

     Γ ⊢ A:B ∧ A →→β A' ⇒ Γ ⊢ A':B
   * Γ ⊢ A:B, тогда A ∈ SN, B ∈ SN.
   * Уникальность типов

     Γ ⊢ B:C; Γ ⊢ B:C' ⟶ C =β C'
   * λ2P !~ λC. Создается видимость, что умея делать функции из типов
     в значения и наоборот, можно сделать термы из типов и типы, но
     формально затипизировать такое выражение можно только Π-правилом,
     но у нас его не будет.
* Ticket 12  Linear and unique types, Combinators BCKIS)
** Линейная логика
   Идея: Мы привыкли, что следующее верно: A, A→B ⊢ A&B, но это
   противоречит наивному пониманию → в интуиционистском смысле. Если A
   -- некоторый объект, то A→B -- способ получить B из A. Тогда после
   использования A→B, A не должно существовать, так как оно было
   использовано для создания B.

   Грамматика:

   T = X | T ⊸ T | A ⊗ B | A & B | A ⊕ B | !A

   A ⊗ B = "и А и B".
   A & B = "выбор между A и B".
   !A = "конечно, А".

   Будем рассматривать две формы предположений: линейные в <>,
   интуиционистские в []. Интуиция -- линейные предположения не могут
   быть сжаты или ослаблены (аксиомы ИИВ). Линейные предположения
   будут встречаться в доказательстве только единажды.

   Если Γ -- это контекст, то [Γ] -- контекст, содержащий только
   интуиционистские посылки. Скобки встречаются только слева от ⊢,
   никогда справа.

   Аксиомы:
   1. Замена        Γ, Δ ⊢ A  ⟶ Δ, Γ ⊢ A
   2. <ID>          () ⟶ <A> ⊢ A
   3. [ID]          () ⟶ [A] ⊢ A
   4. Сокращение    Γ, [A], [A] ⊢ B ⟶ Γ, [A] ⊢ B
   5. Ослабление    Γ ⊢ B ⟶ Γ, [A] ⊢ B
   6. !-I           [Γ] ⊢ A ⟶ [Γ] ⊢ !A
   7. !-E           Γ ⊢ !A; ∆, [A] ⊢ B ⟶ Γ, ∆ ⊢ B
   8. ⊸-I           Γ, <A> ⊢ B      ⟶ Γ ⊢ A ⊸ B
   9. ⊸-E           Γ ⊢ A ⊸ B; Δ ⊢ A ⟶ Γ, Δ ⊢ B
   10. ⊗-I          Γ ⊢ A; Δ ⊢ B ⟶ Γ, Δ ⊢ A ⊗ B
   11. ⊗-E          Γ ⊢ A ⊗ B; Δ, <A>, <B> ⊢ C ⟶ Γ, Δ ⊢ C
   12. &-I          Γ ⊢ A; Γ ⊢ B ⟶ Γ ⊢ A & B
   13. &-E₁         Γ ⊢ A&B ⟶ Γ ⊢ A
   14. &-E₂         Γ ⊢ A&B ⟶ Γ ⊢ B
   15. ⊕-I₁         Γ ⊢ A ⟶ Γ ⊢ A ⊕ B
   16. ⊕-I₂         Γ ⊢ B ⟶ Γ ⊢ A ⊕ B
   17. ⊕-E          Γ ⊢ A ⊗ B; Δ, <A> ⊢ C; Δ, <B> ⊢ C ⟶ Γ, Δ ⊢ C

   Их очень много.

   Вот принипиальная разница между ⊗ и &:
   1. <A> ⊢ C, <A> ⊢ B ⟶ <A>, <A> ⊢ A ⊗ B
   2. <A> ⊢ C, <A> ⊢ B ⟶ <A> ⊢ A & B
   3. <A> ⊢ B ⟶ <A> ⊢ A ⊕ B

   Объясним с помощью аналогии. Пусть A -- десять рублей, тогда
   1. Пицца стоит 10р, пирог стоит 10р ⇒ за 20р можно купить и то, и другое
   2. Пицца стоит 10р, пирог стоит 10р ⇒ за 10р можно купить что-то одно
   3. Пицца стоит 10р ⇒ либо пиццу, либо что-то другое можно купить за 10р

   Можно доказать <A&B> ⊢ A⊗B.

   Нельзя доказать <A> ⊢ A⊗A, <A⊗A> ⊢ A, из-за отсутствия сокращения и
   ослабления в линейной части аксиоматики.

   Если об <A> можно думать как об одной единице A, то [A] -- это
   производитель сколько большого количества A.

   Посмотрим на первые две аксиомы.
   1. <ID> утверждает, что если у нас есть возможность получить 10р,
      то мы можем получить их.
   2. [ID] говорит, что если у нас есть возможность получить сколько угодно десятирублевых купюр, мы можем получить одну.
   3. Можно доказать Γ, <A> ⊢ B ⟶ Γ, [A] ⊢ B -- {⊸-E {⊸-I}
      {[Id]}}. Эта на ходу придуманная нотация значит, что последнее
      доказательство -- это использование ⊸-E правила, для которого
      нужно применить то, что написано после в {}.

   !A объявляет связь между <> и []. Конкретно -- <!A> эквивалентно
   [A]. Правило !-I постулирует, что имей мы A, выведенное из
   контекста, где все бесконечно, мы можем вывести !A -- универсальный
   получатель A.

   [A] ⊢ C ⟶ [A] ⊢ !C -- если я могу купить пиццу исходя из моего
   бесконечного количества десятирублевых купюр, то я могу купить
   сколько угодно пицц.

   Пусть [C] ⊢ D значит, что если у меня будет сколько угодно пицц, я
   буду счастлив. Тогда по правилу !-E ([A] ⊢ !C; [C] ⊢ D) ⟶ [A] ⊢ D.

   Можно доказать Γ, <!A> ⊢ B ⟶  Γ, [A] ⊢ B. {⊸-E {⊸-I} {!-I
   {[ID]}}}. Обратное тоже верно:  Γ, <!A> ⊢ B ⟶  Γ, [A] ⊢ B. {!-E
   {<ID>} утв}.

   Следующие утверждения доказуемы:
   1. !(A & B) ⊢ !A ⊗ !B,
   2. !A ⊗ !B ⊢ !(A & B).

   Давайте выразим связки ИИВ в нашей системе.
   A → B = (!A) ⊸ B
   1. Γ, [A] ⊢ B ⟶ Γ ⊢ (!A) → B.         {⊸-I {!-E {<ID>} expr}}
   2. Γ ⊢ !A → B; [Δ] ⊢ A  ⟶ Γ, [Δ] ⊢ B. {⊸-E expr1 {!-I expr2}}
** Комбинаторная логика
   C = V{переменные} | K | S | (C C)

   Определим на выражениях слабую редукцию →w:
   K F G   →w K
   S F G H →w F H (G H)
   F →w F' ⇒ FG →w F'G и GF → GF'

   →→w - наименьшее рефлексивное, транзитивное отношение,
   удовлетворяющее →w. =w есть →→β с симметричностью. Соттветственно,
   терм в w-нормальной форме -- такой, для которого нет другого, в
   которого можно средуцироваться.

   Определим еще каноничных комбинаторов:
   1. I = SKK, тогда IF →w KF(KF) →w F
   2. SII(SII) = Ω
   3. W = SS(KI), тогда WFG →→w FGG
   4. B = S(KS)K, тогда BFGH →→w F(GH)
   5. C = S(BBS)(KK), тогда CFGH →→w FGH
   6. K, S, KS, SK, SKK в w-нормальной форме.

   Введем дополнительные понятия и докажем леммы:
   1. Свободные переменные:
      FV(x) = {x}
      FV(A B) = FV(A) ∪ FV(B)
      FV(S) = {}
      FV(K) = {}
   2. Подстановка:
      x[x:=G]    = G
      y[x:=G]    = y
      (HE)[x:=G] = H[x:=G] E[x:=G]
      S[x:=G]    = {}
      K[x:=G]    = {}
   3. Теорема Чёрча-Россера для комбинаторов.
      →→w конфлюэнтно.
   4. Определим отношение Λ():
      Λ(x) = x, x ∈ V
      Λ(K) = λxy.x
      Λ(S) = λxyz.xz(yz)
      Λ(FG) = Λ(F) Λ(G)
   5. Теорема о Λ(): Если A →→w B, то Λ(A) →→β Λ(B)
      Доказательство по индукции
   6. Определим λ*x.F ∈ C:
      λ*x.x = I
      λ*x.F = KF, если x ∉FV(F)
      Λ*x.FG = S(λ*x.F)(λ*x.G)
      Это отношение перестраивает терм полностью в комбинаторы.
   7. Лемма о этой новой лямбде: (λ*x.F)G →→w F[x:=G]
   8. Определим отношение C(): Λ → C:
      C(x) = x, x ∈ V
      C(MN) = C(M)C(N)
      C(λx.M) = λ*x.C(M)
   9. Примечание: Неверно, что M →→β N ⇒ C(M) →→w C(N).
      Пример: λx.II →β λx.I, но C(λx.II) = S(KI)(KI) ¬→→w ...
      Проблема в том, что M →w G ¬⇒ λ*x.M →w λ*x.N.
   10. Лемма. ∀M ∈ Λ   Λ(C(M)) =β M
   11. Примечание: Λ() не изоморфизм, поэтому C(Λ(K)) ≠w K.

   Подумаем о типизации комбинаторов, введя следующие правила:
   1. () ⟶ Γ, x:τ ⊢ x:τ
   2. () ⟶ Γ ⊢ K: σ → τ → σ
   3. () ⟶ Γ ⊢ S: (σ → τ → ρ) → (σ → τ) → σ → ρ
   4. Γ ⊢ M:σ → τ; Γ ⊢ N:σ  ⟶ Γ ⊢ M N:τ

   Покажем про них два утверждения (⊢₁ -- вывод в C, ⊢₂ -- вывод в Λ):
   * Лемма: Γ, x:ρ ⊢₁ F:τ, тогда Γ ⊢₁ λ*x.F:ρ→τ
   * Лемма о связи λ→ и C→:
     1. Γ ⊢₁ F:τ ⇒ Γ ⊢₂ Λ(F):τ
     2. Γ ⊢₂ M:τ ⇒ Γ ⊢₁ C(M):τ
* Ticket 13  (F sub <: system)
  Возьмем систему F и приделаем к ней отношение <: на типах.

  Будем писать Top вместо ⊤ ввиду желания использовать букву T.
  Аксиомы:
  1. ()                   ⟶ Γ ⊢ S<:S
  2. Γ ⊢ S<:T; Γ ⊢ T<:U   ⟶ Γ ⊢ S<:U
  3. ()                   ⟶ Γ ⊢ S<:Top
  4. ()                   ⟶ Γ,X<:T ⊢ X<:T
  5. Γ ⊢ T₁<:S₁; Γ ⊢ S₂<:T₂ ⟶ Γ ⊢ (S₁ → S₂) <: (T₁ → T₂)
  6. Γ,X<:U₁ ⊢ S₂<:T₂       ⟶ Γ ⊢ ∀X<:U₁.S₂ <: ∀X:U₁.T₂
  7. Γ ⊢ T₁<:S₁; Γ,X<:T₁ ⊢ S₂<:T₂ ⟶ Γ ⊢ (∀X<:S₁.S₂) <: (∀X<:T₁.T₂)

  На выбор предлагается одна аксиома из {6,7}. Если в системе есть
  только 6, то система называется ядерной Fsub, если только 7, то
  полной Fsub. Вторая система слишком тяжелая, например. Подробнее к
  Пирсу.

  Пятое правило наглядно иллюстрирует тот факт, что функции
  ковариантны по возвращаемому значению и контрвариантны по аргументам.

  Пример 6:
  Γ ⊢ Int <: Top ⟶ Γ ⊢ (∀X<:Top.Int) <: (∀X<:Top.Top)

  Пример 7:
  ... ⟶ (∀X<:Top.List<X>) <: (∀X<:Int.Collection<X>)

  Теперь прикрутим ко всему этому выражения (все аксиомы пока на
  типах). Например, что-нибудь такое:
  1. Γ,X<:T₁ ⊢ t₂:T₂ ⟶ Γ ⊢ (ΛX<:T₁.t₂): ∀X<:T₁.T₂
  2. Γ ⊢ t₁:∀X<:T₁₁.T₁₂;  Γ ⊢ T₂<:T₁₁ ⟶ Γ ⊢ (t₁ T₂):T₁₂[x:=T₂]

  Вот, как будет выглядеть конструктор пары в системе Fsub:

  ΛX<:Top.ΛY<:Top.λx:X.λy:Y(ΛR<:Top.λp:R.X → Y → R.p x y)

  Существует два вида сравнения:
  1. По Лейбницу -- сравниваем предикаты (duck typing).
  2. Принцип объемности -- смотрим внутренности.

  На примере конъюнкции это работает так:
  1. A&B верно, если π₁(A&B) = a && π₂(A&B) = b.
  2. A&B верно, если ∀R((A&B → R) → R)

  Кстати, насчет пар. Можно вывести следующее:
  Γ ⊢ S₁<:T₁; Γ ⊢ S₂<:T₂ ⟶ Γ ⊢ <S₁,S₂> <: <T₁,T₂>

  Доказательство (читать снизу вверх):
                             дано               аксиома
                         -------------------   -------
   дано в условии        Γ, R<:Top ⊢ S₂ <: T₂; Γ ⊢ R<:R
  -------------------   -----------------------------
  Γ, R<:Top ⊢ S₁ <: T₁;  Γ, R<:Top ⊢ (T₂ → R) <: (S₂ → R)      доказывается
  ------------------------------------------------------   -----------------
  Γ, R<:Top ⊢ (T₁ → (T₂ → R)) <: (S₁ → (S₂ → R));              Γ, R<:Top ⊢ R <: R
  ----------------------------------------------------------------------- 5 правило
         Γ, R<:Top ⊢ (S₁ → S₂ → R) → R <: (T₁ → T₂ → R) → R;
  ------------------------------------------------------------- 6 правило
  Γ ⊢ (∀R<:Top.(S₁ → S₂ → R) → R) <: (∀R<:Top.(T₁ → T₂ → R) → R)

  Идея: давайте делать объектно-ориентированное программирование с
  помощью пар.

  struct x{A, B, C} -- <A, <B, <C, Top>>>
  struct y:x {D}    -- <A, <B, <C, <D, Top>>>

  <A, Top> <: <Top, Top>
  <A, <B, Top>> <:? <X, Y> == A <: Y, <B,Top> <: X
  <A, <B, Top>> <: <A, Top>

  Покажем, как с помощью ограниченной квантификации можно выписать
  черчевские нумералы конкретного значения:

  Рассмотрим такой терм на типах:

  Num = ∀X<:Top.∀S<:X.∀Z<:X.(X → S) → (Z → X) -- обобщенный черчевский
  нумерал.

  Тогда ∀X<:Top.∀S<:X.∀Z<:X.(X → S) → (Z → Z) -- тип нулевого
  нумерала.

  ∀X<:Top.∀S<:X.∀Z<:X.(X → S) → (Z → S) -- тип ненулевого нумерала.
* Ticket 14  (λ denotational semantics)
  Существует проблема, заключающаяся в том, что наивное построение
  модели к лямбда-исчислению приводит к парадоксам, как мы это видели
  с парадоксом Карри.

  Пусть у нас есть λx.x, тогда если мы сопоставим ее функции на
  множестве, то неясно, то ли I:D → D, то ли I:(D → D) → (D → D).

  Scratch: сейчас мы построим сложную модель, долго ее будем описывать
  и говорить о леммах, практически ничего не поясняя, а в самом конце
  все объекты свяжем с λ-исчислением.
** Решетки и Dᵢ
   Вспомним определение решетки: <D, E>, ⊔ -- sup, ⊓ -- inf, ⊥, ⊤.
 #   У полной решетки есть неподвижная точка для любой хорошей функции: f(fix f) = fix f.
 #  Давайте разобьем наше вычисление функции на шаги, так что fₙ ⊑ fₙ₊₁, fₘ в нормальной форме -- последнее в цепочке.
   Множество X ⊆ D называется направленным, если X ≠ 0 и ∀a, b ∈ X, ∃c
   ∈ X что a ⊑ c и b ⊑ c.

   Множество называется открытым по Скотту, если:
   1. Оно замкнуто вверх: ∀a∈X (b∈D ∧ a ⊑ b ⇒ b∈X)
   2. ∀T, T -- направленное, тогда если ⊔T∈X, то T∩X ≠ ∅.

   В этом смысле, если проводить аналогию с ℝ, то полуинтервалы будут
   открытыми ([0, 1) -- открыто, (0, 1) -- нет по 2 правилу).

   Пусть дан X, тогда множество его подмножеств T -- топология, если:
   1. ∅, T ∈ T
   2. ⋃{∞}A ∈ T
   3. ⋂{n}A ∈ T

   Множества открытые по Cкотту образуют топологию. Назовем ее
   топологией Скотта.

   Будем рассматривать <P(ℕ), ⊆>. P() -- это булеан. В этом множестве
   есть минимальный элемент ∅. ОБъединение множеств ∈ T.

   Множество {{1}, {2}, {3}, ...} не является открытым по первой части
   определения. {1} ∈ D, {1} ∈ {{1}, {2}}, но {{1}, {2}} ∉ D.

   Окрестность: O(eₙ) = {X | X∈P(ℕ), X≥eₙ}.

   Таким образом в этом примере можно убедиться, что открытость
   множества эквивалентна тому факту, что множество принадлежит T с
   окрестностью любой своей точки.

   # Базис: B - базис, если ∀A - открытое, ∃S⊆B, что ⋃S = A.
   В топологии есть непрерывность -- прообраз любого открытого множества открыт.
   * Теорема. f:D → D' ⇔ X непр, f(⊔X) = ⊔{f(x)|x∈X}
   * Лемма. f:D → D' непрерывно, тогда f монотонно: a ⊑ b ⇒ f(a) ⊑
     f(b).

     Докажем от противного: f(a) ∈ {x | x ∈ D' & x ⋢ f(b)} =: V

     V открыто, тогда по непрерывности прообраз V'=f⁻¹(V) тоже
     открыт. a ∈ V', тогда и b ∈ V' по a ⊑ b и замкнутости
     вверх. Тогда f(b) ∈ V. →←.
   * Декартово произведение:

     D₀×D₁×...×Dₖ₋₁; <d₀,..dₖ₋₁>.
     ⊔X = <⊔d₀,...⊔dₖ₋₁>
   * [D₀ → D₁] -- множество всех отображений из D₀ в D₁.

     f ⊑ g := ∀x.f(x) ⊏ g(x)

     На функциях тоже получится полная решетка. Без доказательства.
   * Лемма. f: D₀ × D₁ → D, f непрерывна ⇔ ∀x₀ f(x₀,y) непрерывна и
     ∀y₀ f(x,y₀) непрерывна.
   * Теорема о непрерывности аппликации.

     D, D' -- полные решетки, тогда (Ap(f,x) = f(x)) : [D → D']×D → D'
     непрерывна.
   * Теорема о непрерывности λ-абстракции. f∈[D×D' → D''], (fλ(x))(y) = f(x, y).
     1. fλ непрерывна.
     2. f → fλ ∈ [[D×D' → D''] → [D → [D' → D'']]]
** Проекции и ∙
   * Проекция.

     Пусть D, D' -- полные решетки, тогда пара отображений:

     φ ∈ [D → D'], ψ ∈ [D' → D]

     назваются проекцией, если ψφ=id∈D, φψ⊑id∈D' (∀x∈D' φψ(x) ⊑ x).
   * Непрерывное отображение p: D → D, такое что p² = p, называется
     ретракцией.
   * Лемма о свойствах проекций.
     1. φ -- изоморфное вложение D в D'
     2. ⊥D, ⊥D' -- боттомы в D и D' соответственно, тогда φ(⊥D) = ⊥D',
        ψ(⊥D') = ⊥D.
     3. φψ -- ретракция.

     Доказательство:
     1. Из непрерывности φ: a ⊑ b ⇒ φ(a) ⊑ φ(b).

        Из непрерывности ψ: φ(a) ⊑ φ(b) ⇒ a = ψφ(a) ⊑ ψφ(b) = b.

        Тогда a ⊑ b ⇔ φ(a) ⊑ φ(b). Отсюда φ(a)=φ(b) ⇒ a=b.
     2. ⊥D' ⊑ φ(⊥D), ψ непрерывна ⇒ ψ(⊥D') ⊑ ψφ(⊥D) = ⊥D ⊑ ψ(⊥D'),
        откуда следует ψ(⊥D') = ⊥D.

        Аналогично, из ⊥D ⊑ ψ(⊥D') и непрерывности φ ⇒ φ(⊥D) ⊑ φψ(⊥D')
        ⊑ ⊥D' ⊑ φ(⊥D) ⇒ φ(⊥D) = ⊥D'
     3. По основным свойствам проекции: (φψ)² = φψφψ = φψ.
   * Мультипроекция:
     φ*: [D → D] → [D' → D']
     ψ*: [D' → D'] → [D → D]
     φ*(f) = φfψ; ψ*(f) = ψfφ.

     Мультипроекця являeтся проекцией.
   * φ₀(x): D → [D → D], ψ₀(f): [D → D] → D
     φ₀(x) = λy.x
     ψ₀(f) = f(⊥)
     (φ₀,ψ₀) -- проекции [D→D] на D.
   * Определим Dᵢ, φᵢ, ψᵢ:
     D₀ = D;
     Dₙ₊₁ = [Dₙ → Dₙ]
     (φₙ₊₁, ψₙ₊₁) = (φ*ₙ, ψ*ₙ)

     Таким образом, мы получили систему полных решеток и гомоморфизмов такого рода:
     D₀ →ψ₀ D₁ →ψ₁ D₂ →ψ₂...
     D₀ φ₀← D₁ φ₁← D₂ φ₂←...
   * D∞ -- искомая модель. D∞ содержит бесконечные последовательности
     x = <x₀,x₁,..>, обозначаемые {xᵢ}, такие, что ψₙ(xₙ₊₁) =
     xₙ. Будем называть последовательность нитью.

     D∞ -- подмножество декартового произведения ∏{i∈ℕ}Dᵢ, с
     покоординатным порядком.
   * Определим функцию Φₙₘ:Dₙ → Dₘ
     Φₙₘ = φₘ₋₁...φₙ(x)    n ≤ m
     Φₙₘ = ψₘ...ψₙ₋₁(x)    n > m
     Φ∞ₙ: D∞ → Dₙ
     Φ∞ₙ({xᵢ}) = xₙ;
     Φₙ∞(x) = {Φₙᵢ}
     Φ∞∞(x) = x
     Φₘₙ, Φₙₘ -- проекция Dₘ на Dₙ;

   Отождествим элементы из Dₙ с элементами D∞. Ввиду того, что для
   каждого n∈ℕ пара <Φₙ∞, Φ∞ₙ> является проекцией D∞ на Dₙ, каждое Φₙ
   является изоморфным вложением из Dₙ в D∞. Поэтому, в некоторм
   смысле, D₀ ⊆ D₁ ⊆ D₂ ⊆ ... ⊆ D∞.

   # Тут должен быть нарисован рисунок, на котором изображены
   # ступеньки, растущие слева направо, каждая вертикальная черта --
   # Dₙ. Подробнее в источники.

   * Много утверждений, которые подробно доказываются, но тут
     приведены без доказательства.
     1. x ∈ Dₙ ⇒ xₙ = x
     2. x ∈ Dₙ ⇒ φₙ(x) = x
     3. x ∈ Dₙ₊₁ ⇒ ψₙ(x) ⊑ x
     4. (xₙ)ₘ = xₘᵢₙ₍ₙ ₘ₎
     5. n ≤ m ⇒ xₙ ⊑ xₘ ⊑ x
     6. TODO добавить ненужных утверждений
   * Операция произведения:

     Пусть Apₙ -- аппликация на Dₙ₊₁ × Dₙ.

     x ∙ y = ⊔ Φₙ∞(Apₙ(Φ∞₍ₙ₊₁₎(x), Φ∞ₙ(y))). Это отображение
     непрерывно на D∞.

     У произведение есть такое свойство: x ∈ Dₙ₊₁, y ∈ Dₙ ⇒ x ∙ y  =
     x(y)

     Читать определение надо так: давайте возьмем два бесконечных
     ряда, будем применять n+1`й элемент первого к n`му элементу
     второго. Потом для каждого такого элемента построим свой ряд
     (см. определение Φₙ∞), и возьмем у него точную верхнюю границу.
   * Теорема о функциональной полноте.

     Пусть f ∈ [D∞ → D∞]. Тогда существует □f ∈ D∞, что
     ∀y ∈ D∞(f(y) = □f ∙ y)

     Пояснение: теорема похожа на кобинатор неподвижной точки (будто
     это что-то прояснило). Пояснение будет в конце.
   * Множества D∞ и [D∞ → D∞] изоморфны и гомеоморфны

     Набросок доказательства: Определим F: D∞ → [D∞ → D∞] как
     λx.λy.x∙y. Тогда обратным к нему будет G: [D∞ → D∞] → D∞. G(f) =
     □f.
   * Для любой непрерывной функции H: Dⁿ∞ → D∞ существует единственное
     a ∈ D∞, что ∀x₁..xₙ∈D∞ | H(x₁...xₙ) = a∙x₁∙x₂∙...
** Семантика Скотта для λ-термов
   Предположим, что каждой переменной приписано некоторое значение из
   D∞. Пусть эта интерпретация переменных задается γ.

   Тогда γₐˣ(x) = a, γₐˣ(y) = γ(y)

   Теперь мы можем естественным образом сопоставить λ-терм с некоторым
   элементом [t]γ ∈ D∞.

   [xᵢ]γ   = γ(xᵢ)
   [A B]γ  = [A]γ∙[B]γ
   [λx.A]γ = □f, где f(a) = [A]γₐˣ для всех a ∈ D∞.

   * Лемма. Для любой интерпретации переменных γ и любых термов t₀, t₁, что t₀ =β t₁, справедливо [t₀]γ = [t₁]γ.
     Доказывается тем, что [A[x:=B]]γ = [A]γ_{[B]}^x. Ну и из этого [(λx.A)B] = [A[x:=B]].

   Пример использования произведения.

   Тут + → ⊔
   a = <⊥, λy.⊥, λxy.x+y, λaxy.x+y, λbaxy.x+y, ...>
   b = <3, λy.3, λxy.3, λaxy.3, λbaxy.3, ...>
   a ∙ b = Φ₀∞{ (λy.⊥) 3 } = Φ₀∞{⊥} = <⊥, λx.⊥, λyx.⊥, λzyx.⊥, ...>
   a ∙ b = Φ₁∞(λxy.x+y)(λy.3) = Φ₁∞{λy.(λz.3) + y} = {⊥, λy.(λz.3) + y, λay.(λz.3) + y, ...}

   Пример плохой, но в общем должно быть понятно, что мы
   делаем. Плохой, потому что формально 3 -- это черчевский нумерал, и
   там еще пара элементов в < ... > будет перед ним, потому что можно
   еще пару боттомов впихнуть. Я надеюсь, что все будет хорошо.

   [λxy.x] = <⊥, λy.⊥, λxy.x, λaxy.x, ...>
   [λz.z]  = <⊥, λz.z, λaz.z, ...>
   ((λxy.x) (λz.z)) = супремум вот этого:
   * <⊥, λa.⊥, λba.⊥, ...>
   * <λz.z, λyz.z, ...>
   * <⊥, λy.⊥ , λxy.x, ...>
   * <⊥, λy.⊥ , λxy.x, ...>
   * <⊥, λy.⊥ , λxy.x, ...>

   Супремум декартового произведения покоординатный, поэтому ответ:
   <λz.z, λyz.z, ...>

   Терм неразрешим, если нет такого набора аргументов, которые можно к
   нему применить, чтобы он пришел в NF.
   * Лемма. Любой неразрешимый терм вычисляется в ⊥.
   * Лемма. Любой неразрешимый терм не имеет заголовочной NF (λxyz.a
     M), где a -- свободная.
